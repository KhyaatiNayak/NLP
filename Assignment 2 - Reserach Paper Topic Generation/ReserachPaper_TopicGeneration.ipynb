{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReserachPaper_TopicGeneration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ZFzPtZqx8Z",
        "outputId": "33d43106-f506-4a66-ec1d-5bd5f8f26fe5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Package abc is already up-to-date!\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Package alpino is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger_ru is already up-to-\n",
            "       |       date!\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Package basque_grammars is already up-to-date!\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Package biocreative_ppi is already up-to-date!\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Package book_grammars is already up-to-date!\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Package brown is already up-to-date!\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Package brown_tei is already up-to-date!\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Package cess_cat is already up-to-date!\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Package cess_esp is already up-to-date!\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Package chat80 is already up-to-date!\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Package city_database is already up-to-date!\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Package cmudict is already up-to-date!\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package comparative_sentences is already up-to-date!\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       |   Package comtrans is already up-to-date!\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Package conll2000 is already up-to-date!\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Package conll2002 is already up-to-date!\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       |   Package conll2007 is already up-to-date!\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Package crubadan is already up-to-date!\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Package dependency_treebank is already up-to-date!\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Package dolch is already up-to-date!\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Package europarl_raw is already up-to-date!\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       |   Package extended_omw is already up-to-date!\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Package floresta is already up-to-date!\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Package framenet_v15 is already up-to-date!\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Package framenet_v17 is already up-to-date!\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Package gazetteers is already up-to-date!\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Package genesis is already up-to-date!\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Package gutenberg is already up-to-date!\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Package ieer is already up-to-date!\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Package inaugural is already up-to-date!\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Package indian is already up-to-date!\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       |   Package jeita is already up-to-date!\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Package kimmo is already up-to-date!\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       |   Package knbc is already up-to-date!\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Package large_grammars is already up-to-date!\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Package lin_thesaurus is already up-to-date!\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Package mac_morpho is already up-to-date!\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       |   Package machado is already up-to-date!\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       |   Package masc_tagged is already up-to-date!\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Package maxent_ne_chunker is already up-to-date!\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package maxent_treebank_pos_tagger is already up-to-date!\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Package moses_sample is already up-to-date!\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Package movie_reviews is already up-to-date!\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Package mte_teip5 is already up-to-date!\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Package mwa_ppdb is already up-to-date!\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Package names is already up-to-date!\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       |   Package nombank.1.0 is already up-to-date!\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package nonbreaking_prefixes is already up-to-date!\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Package nps_chat is already up-to-date!\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Package omw is already up-to-date!\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       |   Package omw-1.4 is already up-to-date!\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Package opinion_lexicon is already up-to-date!\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       |   Package panlex_swadesh is already up-to-date!\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Package paradigms is already up-to-date!\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Package pe08 is already up-to-date!\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Package perluniprops is already up-to-date!\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Package pil is already up-to-date!\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Package pl196x is already up-to-date!\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Package porter_test is already up-to-date!\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Package ppattach is already up-to-date!\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Package problem_reports is already up-to-date!\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Package product_reviews_1 is already up-to-date!\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Package product_reviews_2 is already up-to-date!\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       |   Package propbank is already up-to-date!\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Package pros_cons is already up-to-date!\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Package ptb is already up-to-date!\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Package punkt is already up-to-date!\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Package qc is already up-to-date!\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       |   Package reuters is already up-to-date!\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Package rslp is already up-to-date!\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Package rte is already up-to-date!\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Package sample_grammars is already up-to-date!\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       |   Package semcor is already up-to-date!\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Package senseval is already up-to-date!\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Package sentence_polarity is already up-to-date!\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Package sentiwordnet is already up-to-date!\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Package shakespeare is already up-to-date!\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Package sinica_treebank is already up-to-date!\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Package smultron is already up-to-date!\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       |   Package snowball_data is already up-to-date!\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Package spanish_grammars is already up-to-date!\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Package state_union is already up-to-date!\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Package stopwords is already up-to-date!\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Package subjectivity is already up-to-date!\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Package swadesh is already up-to-date!\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Package switchboard is already up-to-date!\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Package tagsets is already up-to-date!\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Package timit is already up-to-date!\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Package toolbox is already up-to-date!\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Package treebank is already up-to-date!\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Package twitter_samples is already up-to-date!\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Package udhr is already up-to-date!\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Package udhr2 is already up-to-date!\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Package unicode_samples is already up-to-date!\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Package universal_tagset is already up-to-date!\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package universal_treebanks_v20 is already up-to-date!\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       |   Package vader_lexicon is already up-to-date!\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Package verbnet is already up-to-date!\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Package verbnet3 is already up-to-date!\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Package webtext is already up-to-date!\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Package wmt15_eval is already up-to-date!\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Package word2vec_sample is already up-to-date!\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Package wordnet is already up-to-date!\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       |   Package wordnet2021 is already up-to-date!\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       |   Package wordnet31 is already up-to-date!\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Package wordnet_ic is already up-to-date!\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Package words is already up-to-date!\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Package ycoe is already up-to-date!\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "B0XSZKV-y-iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "t1FmbtSlrI7s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# READING DATA"
      ],
      "metadata": {
        "id": "a4J-gv_dzLmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeGm9MjZqDSn",
        "outputId": "593f33be-810c-4b9b-caa8-fe3356ea78af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/NLP datasets/papers.csv', error_bad_lines=False)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "D7qCzMqtrb7k",
        "outputId": "c6aed73d-b8b4-4feb-e877-85c1a3faad4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-decb2735-2ab7-4e1c-9005-92c70b478531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-decb2735-2ab7-4e1c-9005-92c70b478531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-decb2735-2ab7-4e1c-9005-92c70b478531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-decb2735-2ab7-4e1c-9005-92c70b478531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrNE-GSpsRRe",
        "outputId": "1fd0c295-0033-4001-8f9b-661bb7e020fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'year', 'title', 'event_type', 'pdf_name', 'abstract',\n",
              "       'paper_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['paper_text']]\n",
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E9Esf_e5sisB",
        "outputId": "6669dec7-7f86-435b-fc04-42a1bfa35865"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0389954d-ddb3-4cbb-bab3-0862320810b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0389954d-ddb3-4cbb-bab3-0862320810b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0389954d-ddb3-4cbb-bab3-0862320810b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0389954d-ddb3-4cbb-bab3-0862320810b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          paper_text\n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
              "3  Bayesian Query Construction for Neural\\nNetwor...\n",
              "4  Neural Network Ensembles, Cross\\nValidation, a..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJYcFz3Usk5i",
        "outputId": "03ac5b34-66a7-49ca-bb7c-5233a2a184d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7241"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "b5VkJSx1zdOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import re\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
        "from nltk.stem.porter import *\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from string import punctuation\n",
        "np.random.seed(2018)"
      ],
      "metadata": {
        "id": "YefAyiTrsnwc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text']=0"
      ],
      "metadata": {
        "id": "VUYjK9n-spnK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text']=data['paper_text'].str.replace('\\n',' ')"
      ],
      "metadata": {
        "id": "33CEBiFxtRsY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text']=data['clean_text'].apply(lambda x : re.sub('[^a-zA-Z#\\s]*','',x))"
      ],
      "metadata": {
        "id": "Q3gL3HugtTcs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text']=data['clean_text'].apply(lambda x : x.lower())"
      ],
      "metadata": {
        "id": "jmY2UN3TtTe2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0GqDuF7mtThI",
        "outputId": "999b75a4-a501-4a19-ec56-3ac42e63340b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e1c8697-cfe3-4717-be4d-49df512a80ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "      <td>selforganization of associative database and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "      <td>a mean field theory of layer iv of visual co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "      <td>storing covariance by the associative longte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "      <td>bayesian query construction for neural network...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "      <td>neural network ensembles cross validation and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e1c8697-cfe3-4717-be4d-49df512a80ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e1c8697-cfe3-4717-be4d-49df512a80ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e1c8697-cfe3-4717-be4d-49df512a80ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          paper_text  \\\n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...   \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...   \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...   \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...   \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...   \n",
              "\n",
              "                                          clean_text  \n",
              "0    selforganization of associative database and...  \n",
              "1    a mean field theory of layer iv of visual co...  \n",
              "2    storing covariance by the associative longte...  \n",
              "3  bayesian query construction for neural network...  \n",
              "4  neural network ensembles cross validation and ...  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text'] = data['clean_text'].apply(lambda x : ' '.join([w for w in x.split() if len(w)>3]))"
      ],
      "metadata": {
        "id": "846b4gnmtTje"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
        "data['clean_text'] = data['clean_text'].apply(lambda x : ' '.join([w for w in x.split() if not w in stop_words]))"
      ],
      "metadata": {
        "id": "IZVd1P1htTlw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VW1aVhnDtTpM",
        "outputId": "81dca456-3366-4e6d-a8ca-c3b53a36d531"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb5a2d30-7e76-4f2b-9890-a5f619a8b5d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "      <td>selforganization associative database applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "      <td>mean field theory layer visual cortex applicat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "      <td>storing covariance associative longterm potent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "      <td>bayesian query construction neural network mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "      <td>neural network ensembles cross validation acti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb5a2d30-7e76-4f2b-9890-a5f619a8b5d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb5a2d30-7e76-4f2b-9890-a5f619a8b5d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb5a2d30-7e76-4f2b-9890-a5f619a8b5d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          paper_text  \\\n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...   \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...   \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...   \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...   \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  selforganization associative database applicat...  \n",
              "1  mean field theory layer visual cortex applicat...  \n",
              "2  storing covariance associative longterm potent...  \n",
              "3  bayesian query construction neural network mod...  \n",
              "4  neural network ensembles cross validation acti...  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
      ],
      "metadata": {
        "id": "WQ-uJ-oItrw5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text'] = data['clean_text'].apply(lambda y : [lemmatize_stemming(token) for token in gensim.utils.simple_preprocess(y) if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3])"
      ],
      "metadata": {
        "id": "A8P4HUdgtt8i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['clean_text'] = data['clean_text'].apply(' '.join)"
      ],
      "metadata": {
        "id": "7SiEoxfot6XQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['newcol'] = data['clean_text'].apply(lambda x : x.split())"
      ],
      "metadata": {
        "id": "6RmGMzW3vDjk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0zaDYsYCvFs5",
        "outputId": "840a3a7d-015a-4003-90f0-e6ed15837d60"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b377322c-1939-4d2f-a7e1-08587a894cc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>newcol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "      <td>associ databas applic hisashi suzuki suguru ar...</td>\n",
              "      <td>[associ, databas, applic, hisashi, suzuki, sug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "      <td>mean field theori layer visual cortex applic a...</td>\n",
              "      <td>[mean, field, theori, layer, visual, cortex, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "      <td>store covari associ longterm potenti depress s...</td>\n",
              "      <td>[store, covari, associ, longterm, potenti, dep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "      <td>bayesian queri construct neural network model ...</td>\n",
              "      <td>[bayesian, queri, construct, neural, network, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "      <td>neural network ensembl cross valid activ learn...</td>\n",
              "      <td>[neural, network, ensembl, cross, valid, activ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b377322c-1939-4d2f-a7e1-08587a894cc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b377322c-1939-4d2f-a7e1-08587a894cc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b377322c-1939-4d2f-a7e1-08587a894cc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          paper_text  \\\n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...   \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...   \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...   \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...   \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...   \n",
              "\n",
              "                                          clean_text  \\\n",
              "0  associ databas applic hisashi suzuki suguru ar...   \n",
              "1  mean field theori layer visual cortex applic a...   \n",
              "2  store covari associ longterm potenti depress s...   \n",
              "3  bayesian queri construct neural network model ...   \n",
              "4  neural network ensembl cross valid activ learn...   \n",
              "\n",
              "                                              newcol  \n",
              "0  [associ, databas, applic, hisashi, suzuki, sug...  \n",
              "1  [mean, field, theori, layer, visual, cortex, a...  \n",
              "2  [store, covari, associ, longterm, potenti, dep...  \n",
              "3  [bayesian, queri, construct, neural, network, ...  \n",
              "4  [neural, network, ensembl, cross, valid, activ...  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORD EMBEDDING"
      ],
      "metadata": {
        "id": "9Vdx49ZHz0_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(data['newcol'])"
      ],
      "metadata": {
        "id": "VRrhF0uvvzRR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lEoA6V8v3cF",
        "outputId": "45ab27c7-ac46-48bb-de46-9482633ec8fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 abolish\n",
            "1 abstract\n",
            "2 acceler\n",
            "3 accept\n",
            "4 accomplish\n",
            "5 accord\n",
            "6 achiev\n",
            "7 actual\n",
            "8 adap\n",
            "9 address\n",
            "10 adjac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BAG OF WORDS"
      ],
      "metadata": {
        "id": "kLqRBjbuzh2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in data['newcol']]\n",
        "bow_corpus[4310]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmwx7IU3vHPs",
        "outputId": "c2db23e4-ac49-4be5-a509-8ba20c9acf4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (2, 1),\n",
              " (6, 17),\n",
              " (7, 1),\n",
              " (14, 46),\n",
              " (20, 13),\n",
              " (26, 3),\n",
              " (27, 5),\n",
              " (28, 1),\n",
              " (29, 29),\n",
              " (31, 3),\n",
              " (33, 1),\n",
              " (39, 2),\n",
              " (41, 1),\n",
              " (42, 9),\n",
              " (44, 1),\n",
              " (49, 2),\n",
              " (52, 4),\n",
              " (54, 6),\n",
              " (55, 1),\n",
              " (56, 1),\n",
              " (72, 4),\n",
              " (76, 2),\n",
              " (77, 1),\n",
              " (79, 1),\n",
              " (90, 1),\n",
              " (93, 4),\n",
              " (94, 7),\n",
              " (98, 4),\n",
              " (100, 1),\n",
              " (103, 1),\n",
              " (105, 28),\n",
              " (107, 2),\n",
              " (109, 2),\n",
              " (113, 5),\n",
              " (114, 32),\n",
              " (116, 1),\n",
              " (117, 4),\n",
              " (118, 3),\n",
              " (125, 3),\n",
              " (128, 16),\n",
              " (133, 4),\n",
              " (137, 10),\n",
              " (138, 4),\n",
              " (141, 2),\n",
              " (145, 3),\n",
              " (148, 2),\n",
              " (151, 2),\n",
              " (152, 1),\n",
              " (155, 2),\n",
              " (158, 12),\n",
              " (159, 1),\n",
              " (165, 1),\n",
              " (168, 5),\n",
              " (169, 4),\n",
              " (177, 3),\n",
              " (179, 3),\n",
              " (180, 9),\n",
              " (182, 1),\n",
              " (184, 14),\n",
              " (186, 3),\n",
              " (188, 2),\n",
              " (190, 4),\n",
              " (193, 6),\n",
              " (194, 7),\n",
              " (195, 1),\n",
              " (199, 1),\n",
              " (205, 3),\n",
              " (206, 2),\n",
              " (210, 5),\n",
              " (213, 8),\n",
              " (214, 2),\n",
              " (218, 3),\n",
              " (221, 15),\n",
              " (226, 2),\n",
              " (227, 4),\n",
              " (228, 5),\n",
              " (229, 2),\n",
              " (238, 1),\n",
              " (253, 1),\n",
              " (261, 1),\n",
              " (262, 2),\n",
              " (264, 1),\n",
              " (265, 6),\n",
              " (266, 2),\n",
              " (269, 2),\n",
              " (271, 1),\n",
              " (273, 3),\n",
              " (274, 3),\n",
              " (286, 1),\n",
              " (294, 3),\n",
              " (295, 1),\n",
              " (300, 1),\n",
              " (303, 8),\n",
              " (305, 10),\n",
              " (306, 8),\n",
              " (308, 1),\n",
              " (309, 2),\n",
              " (310, 4),\n",
              " (312, 1),\n",
              " (313, 1),\n",
              " (315, 4),\n",
              " (321, 18),\n",
              " (324, 7),\n",
              " (326, 1),\n",
              " (330, 1),\n",
              " (331, 1),\n",
              " (332, 2),\n",
              " (334, 5),\n",
              " (338, 12),\n",
              " (340, 8),\n",
              " (343, 5),\n",
              " (349, 1),\n",
              " (357, 1),\n",
              " (364, 3),\n",
              " (365, 9),\n",
              " (367, 9),\n",
              " (371, 3),\n",
              " (372, 9),\n",
              " (376, 4),\n",
              " (377, 2),\n",
              " (380, 4),\n",
              " (384, 2),\n",
              " (385, 7),\n",
              " (391, 15),\n",
              " (395, 1),\n",
              " (397, 17),\n",
              " (399, 2),\n",
              " (401, 4),\n",
              " (402, 1),\n",
              " (409, 2),\n",
              " (410, 14),\n",
              " (411, 3),\n",
              " (413, 3),\n",
              " (414, 1),\n",
              " (416, 3),\n",
              " (417, 1),\n",
              " (418, 4),\n",
              " (419, 7),\n",
              " (423, 1),\n",
              " (424, 1),\n",
              " (426, 28),\n",
              " (429, 3),\n",
              " (437, 7),\n",
              " (439, 1),\n",
              " (440, 4),\n",
              " (445, 2),\n",
              " (447, 4),\n",
              " (450, 2),\n",
              " (452, 2),\n",
              " (453, 1),\n",
              " (455, 12),\n",
              " (463, 2),\n",
              " (470, 2),\n",
              " (474, 1),\n",
              " (476, 4),\n",
              " (477, 12),\n",
              " (478, 1),\n",
              " (483, 4),\n",
              " (485, 12),\n",
              " (486, 6),\n",
              " (487, 1),\n",
              " (488, 1),\n",
              " (489, 1),\n",
              " (490, 1),\n",
              " (491, 6),\n",
              " (493, 4),\n",
              " (495, 1),\n",
              " (496, 4),\n",
              " (498, 2),\n",
              " (499, 2),\n",
              " (501, 3),\n",
              " (507, 12),\n",
              " (508, 1),\n",
              " (510, 4),\n",
              " (511, 5),\n",
              " (513, 22),\n",
              " (517, 10),\n",
              " (536, 4),\n",
              " (543, 1),\n",
              " (544, 1),\n",
              " (549, 6),\n",
              " (550, 1),\n",
              " (554, 6),\n",
              " (559, 8),\n",
              " (570, 10),\n",
              " (572, 1),\n",
              " (573, 1),\n",
              " (574, 1),\n",
              " (577, 2),\n",
              " (578, 3),\n",
              " (580, 11),\n",
              " (581, 5),\n",
              " (593, 1),\n",
              " (598, 1),\n",
              " (606, 3),\n",
              " (608, 1),\n",
              " (613, 1),\n",
              " (614, 1),\n",
              " (615, 3),\n",
              " (623, 16),\n",
              " (625, 1),\n",
              " (626, 1),\n",
              " (627, 48),\n",
              " (630, 4),\n",
              " (631, 10),\n",
              " (650, 7),\n",
              " (652, 2),\n",
              " (654, 8),\n",
              " (657, 27),\n",
              " (658, 1),\n",
              " (676, 1),\n",
              " (677, 4),\n",
              " (682, 4),\n",
              " (695, 1),\n",
              " (696, 3),\n",
              " (697, 3),\n",
              " (704, 9),\n",
              " (705, 1),\n",
              " (706, 1),\n",
              " (709, 8),\n",
              " (712, 1),\n",
              " (715, 1),\n",
              " (716, 5),\n",
              " (723, 1),\n",
              " (727, 1),\n",
              " (732, 1),\n",
              " (734, 4),\n",
              " (741, 10),\n",
              " (745, 4),\n",
              " (761, 2),\n",
              " (771, 2),\n",
              " (773, 6),\n",
              " (774, 9),\n",
              " (782, 1),\n",
              " (785, 3),\n",
              " (791, 1),\n",
              " (792, 1),\n",
              " (793, 1),\n",
              " (794, 1),\n",
              " (795, 2),\n",
              " (798, 3),\n",
              " (800, 7),\n",
              " (804, 1),\n",
              " (806, 2),\n",
              " (812, 1),\n",
              " (813, 4),\n",
              " (815, 1),\n",
              " (818, 1),\n",
              " (823, 9),\n",
              " (826, 3),\n",
              " (828, 5),\n",
              " (833, 2),\n",
              " (834, 3),\n",
              " (837, 2),\n",
              " (843, 1),\n",
              " (845, 1),\n",
              " (847, 40),\n",
              " (852, 3),\n",
              " (853, 12),\n",
              " (856, 3),\n",
              " (857, 25),\n",
              " (858, 1),\n",
              " (859, 1),\n",
              " (860, 1),\n",
              " (865, 2),\n",
              " (872, 1),\n",
              " (873, 1),\n",
              " (876, 3),\n",
              " (923, 2),\n",
              " (928, 6),\n",
              " (950, 2),\n",
              " (973, 1),\n",
              " (977, 1),\n",
              " (987, 3),\n",
              " (1024, 3),\n",
              " (1037, 3),\n",
              " (1051, 5),\n",
              " (1055, 27),\n",
              " (1073, 1),\n",
              " (1106, 4),\n",
              " (1109, 1),\n",
              " (1111, 1),\n",
              " (1112, 4),\n",
              " (1114, 3),\n",
              " (1136, 1),\n",
              " (1142, 1),\n",
              " (1150, 1),\n",
              " (1161, 1),\n",
              " (1178, 2),\n",
              " (1180, 7),\n",
              " (1181, 3),\n",
              " (1182, 1),\n",
              " (1197, 3),\n",
              " (1198, 1),\n",
              " (1199, 1),\n",
              " (1208, 8),\n",
              " (1224, 3),\n",
              " (1229, 20),\n",
              " (1232, 2),\n",
              " (1243, 15),\n",
              " (1257, 7),\n",
              " (1270, 2),\n",
              " (1271, 1),\n",
              " (1272, 1),\n",
              " (1276, 1),\n",
              " (1279, 3),\n",
              " (1284, 1),\n",
              " (1292, 1),\n",
              " (1305, 27),\n",
              " (1306, 1),\n",
              " (1308, 1),\n",
              " (1311, 5),\n",
              " (1317, 4),\n",
              " (1319, 1),\n",
              " (1320, 3),\n",
              " (1324, 1),\n",
              " (1328, 1),\n",
              " (1331, 2),\n",
              " (1339, 4),\n",
              " (1345, 1),\n",
              " (1346, 3),\n",
              " (1350, 2),\n",
              " (1353, 1),\n",
              " (1355, 2),\n",
              " (1356, 1),\n",
              " (1359, 1),\n",
              " (1365, 2),\n",
              " (1371, 1),\n",
              " (1383, 1),\n",
              " (1385, 9),\n",
              " (1390, 1),\n",
              " (1391, 3),\n",
              " (1395, 1),\n",
              " (1409, 1),\n",
              " (1410, 1),\n",
              " (1411, 2),\n",
              " (1414, 1),\n",
              " (1418, 7),\n",
              " (1430, 1),\n",
              " (1434, 1),\n",
              " (1443, 1),\n",
              " (1445, 1),\n",
              " (1447, 4),\n",
              " (1451, 1),\n",
              " (1452, 1),\n",
              " (1463, 2),\n",
              " (1472, 1),\n",
              " (1473, 2),\n",
              " (1482, 1),\n",
              " (1483, 3),\n",
              " (1485, 2),\n",
              " (1489, 12),\n",
              " (1491, 2),\n",
              " (1493, 2),\n",
              " (1495, 12),\n",
              " (1496, 1),\n",
              " (1503, 1),\n",
              " (1505, 2),\n",
              " (1508, 2),\n",
              " (1511, 1),\n",
              " (1512, 8),\n",
              " (1515, 1),\n",
              " (1521, 1),\n",
              " (1525, 1),\n",
              " (1526, 1),\n",
              " (1544, 7),\n",
              " (1597, 18),\n",
              " (1619, 2),\n",
              " (1639, 2),\n",
              " (1654, 3),\n",
              " (1655, 2),\n",
              " (1664, 1),\n",
              " (1665, 1),\n",
              " (1679, 1),\n",
              " (1689, 1),\n",
              " (1707, 1),\n",
              " (1710, 2),\n",
              " (1724, 1),\n",
              " (1736, 1),\n",
              " (1740, 1),\n",
              " (1742, 4),\n",
              " (1744, 2),\n",
              " (1745, 10),\n",
              " (1757, 1),\n",
              " (1762, 2),\n",
              " (1790, 1),\n",
              " (1795, 1),\n",
              " (1796, 1),\n",
              " (1799, 1),\n",
              " (1808, 1),\n",
              " (1813, 3),\n",
              " (1822, 5),\n",
              " (1825, 31),\n",
              " (1845, 3),\n",
              " (1848, 2),\n",
              " (1857, 4),\n",
              " (1869, 5),\n",
              " (1912, 2),\n",
              " (1936, 1),\n",
              " (1950, 2),\n",
              " (1971, 1),\n",
              " (1998, 3),\n",
              " (2013, 2),\n",
              " (2024, 4),\n",
              " (2030, 1),\n",
              " (2032, 1),\n",
              " (2037, 1),\n",
              " (2039, 2),\n",
              " (2067, 1),\n",
              " (2068, 1),\n",
              " (2107, 1),\n",
              " (2123, 2),\n",
              " (2147, 1),\n",
              " (2189, 1),\n",
              " (2192, 1),\n",
              " (2199, 1),\n",
              " (2249, 1),\n",
              " (2281, 1),\n",
              " (2317, 1),\n",
              " (2325, 1),\n",
              " (2338, 2),\n",
              " (2344, 1),\n",
              " (2370, 3),\n",
              " (2375, 5),\n",
              " (2389, 7),\n",
              " (2416, 1),\n",
              " (2424, 1),\n",
              " (2433, 3),\n",
              " (2462, 1),\n",
              " (2506, 1),\n",
              " (2541, 1),\n",
              " (2560, 1),\n",
              " (2576, 1),\n",
              " (2592, 2),\n",
              " (2596, 2),\n",
              " (2597, 2),\n",
              " (2635, 1),\n",
              " (2698, 1),\n",
              " (2711, 1),\n",
              " (2713, 1),\n",
              " (2963, 2),\n",
              " (2977, 2),\n",
              " (3015, 1),\n",
              " (3053, 1),\n",
              " (3081, 1),\n",
              " (3122, 2),\n",
              " (3125, 1),\n",
              " (3139, 1),\n",
              " (3217, 1),\n",
              " (3226, 2),\n",
              " (3271, 1),\n",
              " (3337, 2),\n",
              " (3345, 1),\n",
              " (3359, 2),\n",
              " (3391, 3),\n",
              " (3452, 1),\n",
              " (3474, 1),\n",
              " (3564, 1),\n",
              " (3576, 1),\n",
              " (3579, 1),\n",
              " (3627, 2),\n",
              " (3629, 1),\n",
              " (3646, 5),\n",
              " (3722, 2),\n",
              " (3756, 5),\n",
              " (3782, 3),\n",
              " (3876, 2),\n",
              " (3884, 1),\n",
              " (3904, 1),\n",
              " (3957, 1),\n",
              " (4027, 1),\n",
              " (4059, 1),\n",
              " (4060, 5),\n",
              " (4091, 1),\n",
              " (4107, 1),\n",
              " (4110, 5),\n",
              " (4157, 2),\n",
              " (4182, 1),\n",
              " (4250, 2),\n",
              " (4307, 1),\n",
              " (4316, 2),\n",
              " (4320, 16),\n",
              " (4332, 1),\n",
              " (4336, 1),\n",
              " (4353, 2),\n",
              " (4368, 17),\n",
              " (4377, 1),\n",
              " (4392, 4),\n",
              " (4395, 2),\n",
              " (4407, 1),\n",
              " (4419, 1),\n",
              " (4453, 2),\n",
              " (4619, 2),\n",
              " (4715, 36),\n",
              " (4770, 1),\n",
              " (4785, 3),\n",
              " (4804, 1),\n",
              " (4844, 1),\n",
              " (4851, 1),\n",
              " (4971, 1),\n",
              " (4980, 1),\n",
              " (4987, 6),\n",
              " (5006, 1),\n",
              " (5062, 1),\n",
              " (5083, 1),\n",
              " (5262, 1),\n",
              " (5441, 1),\n",
              " (5560, 2),\n",
              " (5596, 1),\n",
              " (5763, 1),\n",
              " (5793, 1),\n",
              " (5827, 1),\n",
              " (5871, 1),\n",
              " (6016, 1),\n",
              " (6060, 1),\n",
              " (6070, 1),\n",
              " (6168, 1),\n",
              " (6186, 9),\n",
              " (6340, 1),\n",
              " (6854, 1),\n",
              " (6862, 2),\n",
              " (6869, 1),\n",
              " (6906, 1),\n",
              " (6953, 1),\n",
              " (6962, 21),\n",
              " (7068, 1),\n",
              " (7174, 1),\n",
              " (7453, 1),\n",
              " (7589, 6),\n",
              " (7669, 1),\n",
              " (7687, 1),\n",
              " (8119, 1),\n",
              " (8235, 1),\n",
              " (8520, 1),\n",
              " (8720, 1),\n",
              " (8876, 1),\n",
              " (9212, 9),\n",
              " (9847, 1),\n",
              " (10024, 1),\n",
              " (10553, 2),\n",
              " (10789, 16),\n",
              " (11676, 1),\n",
              " (12500, 1),\n",
              " (12506, 1),\n",
              " (12520, 1),\n",
              " (12522, 1),\n",
              " (12538, 1),\n",
              " (15170, 2),\n",
              " (16697, 1),\n",
              " (17408, 1),\n",
              " (17424, 1),\n",
              " (18343, 1),\n",
              " (18768, 1),\n",
              " (19121, 1),\n",
              " (19566, 1),\n",
              " (19719, 1),\n",
              " (20274, 2),\n",
              " (20316, 2),\n",
              " (20575, 7),\n",
              " (20859, 1),\n",
              " (20928, 1),\n",
              " (21206, 1),\n",
              " (22700, 1),\n",
              " (22757, 4),\n",
              " (23458, 3),\n",
              " (25312, 1),\n",
              " (27425, 3),\n",
              " (28562, 1),\n",
              " (28672, 1),\n",
              " (29171, 2),\n",
              " (29328, 1),\n",
              " (29393, 1),\n",
              " (30735, 1),\n",
              " (30972, 1),\n",
              " (33657, 1),\n",
              " (34355, 1),\n",
              " (34415, 2),\n",
              " (35701, 1),\n",
              " (36750, 4),\n",
              " (36856, 8),\n",
              " (38267, 3),\n",
              " (38650, 1),\n",
              " (41541, 1),\n",
              " (43712, 11),\n",
              " (45644, 8),\n",
              " (46144, 1),\n",
              " (49104, 1),\n",
              " (50916, 3),\n",
              " (56529, 2),\n",
              " (56530, 1),\n",
              " (56902, 1),\n",
              " (57246, 1),\n",
              " (57312, 1),\n",
              " (57884, 1),\n",
              " (62410, 1),\n",
              " (62469, 1),\n",
              " (68030, 1),\n",
              " (70053, 4),\n",
              " (70753, 1),\n",
              " (72396, 2),\n",
              " (73811, 2),\n",
              " (74170, 1),\n",
              " (78199, 1),\n",
              " (78727, 1),\n",
              " (79177, 1),\n",
              " (79516, 1),\n",
              " (79546, 1),\n",
              " (81934, 1),\n",
              " (83851, 2),\n",
              " (88020, 1),\n",
              " (88880, 2),\n",
              " (89357, 1),\n",
              " (89884, 1),\n",
              " (91192, 2),\n",
              " (91194, 1),\n",
              " (92761, 1),\n",
              " (93351, 1),\n",
              " (97857, 1),\n",
              " (101092, 1),\n",
              " (103252, 2),\n",
              " (113135, 12),\n",
              " (121602, 1),\n",
              " (121608, 2),\n",
              " (130760, 2),\n",
              " (137784, 1),\n",
              " (137785, 1),\n",
              " (137786, 1),\n",
              " (137787, 1),\n",
              " (137788, 1),\n",
              " (137789, 1),\n",
              " (137790, 1),\n",
              " (137791, 1),\n",
              " (137792, 1),\n",
              " (137793, 1),\n",
              " (137794, 1),\n",
              " (137795, 1),\n",
              " (137796, 1),\n",
              " (137797, 1),\n",
              " (137798, 10),\n",
              " (137799, 2),\n",
              " (137800, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                                     dictionary[bow_doc_4310[i][0]], \n",
        "                                                     bow_doc_4310[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85lnIjP2vMQ7",
        "outputId": "dc530d69-a6f9-48ee-ba89-1ad8c5cd3f1e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 1 (\"abstract\") appears 1 time.\n",
            "Word 2 (\"acceler\") appears 1 time.\n",
            "Word 6 (\"achiev\") appears 17 time.\n",
            "Word 7 (\"actual\") appears 1 time.\n",
            "Word 14 (\"algorithm\") appears 46 time.\n",
            "Word 20 (\"analysi\") appears 13 time.\n",
            "Word 26 (\"applic\") appears 3 time.\n",
            "Word 27 (\"approach\") appears 5 time.\n",
            "Word 28 (\"appropri\") appears 1 time.\n",
            "Word 29 (\"approxim\") appears 29 time.\n",
            "Word 31 (\"arbitrarili\") appears 3 time.\n",
            "Word 33 (\"area\") appears 1 time.\n",
            "Word 39 (\"aspect\") appears 2 time.\n",
            "Word 41 (\"associ\") appears 1 time.\n",
            "Word 42 (\"assum\") appears 9 time.\n",
            "Word 44 (\"attain\") appears 1 time.\n",
            "Word 49 (\"avoid\") appears 2 time.\n",
            "Word 52 (\"base\") appears 4 time.\n",
            "Word 54 (\"better\") appears 6 time.\n",
            "Word 55 (\"binari\") appears 1 time.\n",
            "Word 56 (\"black\") appears 1 time.\n",
            "Word 72 (\"case\") appears 4 time.\n",
            "Word 76 (\"chang\") appears 2 time.\n",
            "Word 77 (\"chapter\") appears 1 time.\n",
            "Word 79 (\"check\") appears 1 time.\n",
            "Word 90 (\"combin\") appears 1 time.\n",
            "Word 93 (\"compar\") appears 4 time.\n",
            "Word 94 (\"complex\") appears 7 time.\n",
            "Word 98 (\"comput\") appears 4 time.\n",
            "Word 100 (\"conclus\") appears 1 time.\n",
            "Word 103 (\"connect\") appears 1 time.\n",
            "Word 105 (\"consid\") appears 28 time.\n",
            "Word 107 (\"consist\") appears 2 time.\n",
            "Word 109 (\"construct\") appears 2 time.\n",
            "Word 113 (\"control\") appears 5 time.\n",
            "Word 114 (\"converg\") appears 32 time.\n",
            "Word 116 (\"correl\") appears 1 time.\n",
            "Word 117 (\"correspond\") appears 4 time.\n",
            "Word 118 (\"cost\") appears 3 time.\n",
            "Word 125 (\"current\") appears 3 time.\n",
            "Word 128 (\"data\") appears 16 time.\n",
            "Word 133 (\"defin\") appears 4 time.\n",
            "Word 137 (\"denot\") appears 10 time.\n",
            "Word 138 (\"depend\") appears 4 time.\n",
            "Word 141 (\"desir\") appears 2 time.\n",
            "Word 145 (\"differ\") appears 3 time.\n",
            "Word 148 (\"direct\") appears 2 time.\n",
            "Word 151 (\"discuss\") appears 2 time.\n",
            "Word 152 (\"display\") appears 1 time.\n",
            "Word 155 (\"distanc\") appears 2 time.\n",
            "Word 158 (\"distribut\") appears 12 time.\n",
            "Word 159 (\"divid\") appears 1 time.\n",
            "Word 165 (\"easi\") appears 1 time.\n",
            "Word 168 (\"effect\") appears 5 time.\n",
            "Word 169 (\"effici\") appears 4 time.\n",
            "Word 177 (\"equal\") appears 3 time.\n",
            "Word 179 (\"equival\") appears 3 time.\n",
            "Word 180 (\"error\") appears 9 time.\n",
            "Word 182 (\"essenti\") appears 1 time.\n",
            "Word 184 (\"estim\") appears 14 time.\n",
            "Word 186 (\"euclidean\") appears 3 time.\n",
            "Word 188 (\"exampl\") appears 2 time.\n",
            "Word 190 (\"excess\") appears 4 time.\n",
            "Word 193 (\"exist\") appears 6 time.\n",
            "Word 194 (\"experi\") appears 7 time.\n",
            "Word 195 (\"experiment\") appears 1 time.\n",
            "Word 199 (\"face\") appears 1 time.\n",
            "Word 205 (\"fast\") appears 3 time.\n",
            "Word 206 (\"faster\") appears 2 time.\n",
            "Word 210 (\"finit\") appears 5 time.\n",
            "Word 213 (\"follow\") appears 8 time.\n",
            "Word 214 (\"form\") appears 2 time.\n",
            "Word 218 (\"framework\") appears 3 time.\n",
            "Word 221 (\"function\") appears 15 time.\n",
            "Word 226 (\"generat\") appears 2 time.\n",
            "Word 227 (\"give\") appears 4 time.\n",
            "Word 228 (\"global\") appears 5 time.\n",
            "Word 229 (\"good\") appears 2 time.\n",
            "Word 238 (\"hard\") appears 1 time.\n",
            "Word 253 (\"ieee\") appears 1 time.\n",
            "Word 261 (\"implement\") appears 1 time.\n",
            "Word 262 (\"impli\") appears 2 time.\n",
            "Word 264 (\"impos\") appears 1 time.\n",
            "Word 265 (\"improv\") appears 6 time.\n",
            "Word 266 (\"includ\") appears 2 time.\n",
            "Word 269 (\"increas\") appears 2 time.\n",
            "Word 271 (\"infinit\") appears 1 time.\n",
            "Word 273 (\"initi\") appears 3 time.\n",
            "Word 274 (\"input\") appears 3 time.\n",
            "Word 286 (\"introduct\") appears 1 time.\n",
            "Word 294 (\"know\") appears 3 time.\n",
            "Word 295 (\"knowledg\") appears 1 time.\n",
            "Word 300 (\"lack\") appears 1 time.\n",
            "Word 303 (\"larg\") appears 8 time.\n",
            "Word 305 (\"learn\") appears 10 time.\n",
            "Word 306 (\"leav\") appears 8 time.\n",
            "Word 308 (\"letter\") appears 1 time.\n",
            "Word 309 (\"level\") appears 2 time.\n",
            "Word 310 (\"like\") appears 4 time.\n",
            "Word 312 (\"limit\") appears 1 time.\n",
            "Word 313 (\"line\") appears 1 time.\n",
            "Word 315 (\"local\") appears 4 time.\n",
            "Word 321 (\"loss\") appears 18 time.\n",
            "Word 324 (\"machin\") appears 7 time.\n",
            "Word 326 (\"main\") appears 1 time.\n",
            "Word 330 (\"mark\") appears 1 time.\n",
            "Word 331 (\"match\") appears 1 time.\n",
            "Word 332 (\"mathemat\") appears 2 time.\n",
            "Word 334 (\"mean\") appears 5 time.\n",
            "Word 338 (\"method\") appears 12 time.\n",
            "Word 340 (\"minim\") appears 8 time.\n",
            "Word 343 (\"model\") appears 5 time.\n",
            "Word 349 (\"natur\") appears 1 time.\n",
            "Word 357 (\"neural\") appears 1 time.\n",
            "Word 364 (\"number\") appears 3 time.\n",
            "Word 365 (\"observ\") appears 9 time.\n",
            "Word 367 (\"obtain\") appears 9 time.\n",
            "Word 371 (\"oper\") appears 3 time.\n",
            "Word 372 (\"order\") appears 9 time.\n",
            "Word 376 (\"output\") appears 4 time.\n",
            "Word 377 (\"pair\") appears 2 time.\n",
            "Word 380 (\"paper\") appears 4 time.\n",
            "Word 384 (\"partial\") appears 2 time.\n",
            "Word 385 (\"pass\") appears 7 time.\n",
            "Word 391 (\"perform\") appears 15 time.\n",
            "Word 395 (\"play\") appears 1 time.\n",
            "Word 397 (\"point\") appears 17 time.\n",
            "Word 399 (\"posit\") appears 2 time.\n",
            "Word 401 (\"practic\") appears 4 time.\n",
            "Word 402 (\"precis\") appears 1 time.\n",
            "Word 409 (\"probabl\") appears 2 time.\n",
            "Word 410 (\"problem\") appears 14 time.\n",
            "Word 411 (\"procedur\") appears 3 time.\n",
            "Word 413 (\"process\") appears 3 time.\n",
            "Word 414 (\"produc\") appears 1 time.\n",
            "Word 416 (\"project\") appears 3 time.\n",
            "Word 417 (\"proper\") appears 1 time.\n",
            "Word 418 (\"properti\") appears 4 time.\n",
            "Word 419 (\"proport\") appears 7 time.\n",
            "Word 423 (\"quick\") appears 1 time.\n",
            "Word 424 (\"random\") appears 1 time.\n",
            "Word 426 (\"rate\") appears 28 time.\n",
            "Word 429 (\"real\") appears 3 time.\n",
            "Word 437 (\"recurs\") appears 7 time.\n",
            "Word 439 (\"reduc\") appears 1 time.\n",
            "Word 440 (\"refer\") appears 4 time.\n",
            "Word 445 (\"remain\") appears 2 time.\n",
            "Word 447 (\"report\") appears 4 time.\n",
            "Word 450 (\"research\") appears 2 time.\n",
            "Word 452 (\"respect\") appears 2 time.\n",
            "Word 453 (\"respons\") appears 1 time.\n",
            "Word 455 (\"result\") appears 12 time.\n",
            "Word 463 (\"role\") appears 2 time.\n",
            "Word 470 (\"sampl\") appears 2 time.\n",
            "Word 474 (\"scienc\") appears 1 time.\n",
            "Word 476 (\"second\") appears 4 time.\n",
            "Word 477 (\"section\") appears 12 time.\n",
            "Word 478 (\"select\") appears 1 time.\n",
            "Word 483 (\"sequenc\") appears 4 time.\n",
            "Word 485 (\"show\") appears 12 time.\n",
            "Word 486 (\"similar\") appears 6 time.\n",
            "Word 487 (\"simpl\") appears 1 time.\n",
            "Word 488 (\"simplest\") appears 1 time.\n",
            "Word 489 (\"singl\") appears 1 time.\n",
            "Word 490 (\"situat\") appears 1 time.\n",
            "Word 491 (\"size\") appears 6 time.\n",
            "Word 493 (\"slight\") appears 4 time.\n",
            "Word 495 (\"slowli\") appears 1 time.\n",
            "Word 496 (\"small\") appears 4 time.\n",
            "Word 498 (\"solut\") appears 2 time.\n",
            "Word 499 (\"solv\") appears 2 time.\n",
            "Word 501 (\"space\") appears 3 time.\n",
            "Word 507 (\"squar\") appears 12 time.\n",
            "Word 508 (\"stage\") appears 1 time.\n",
            "Word 510 (\"start\") appears 4 time.\n",
            "Word 511 (\"stationari\") appears 5 time.\n",
            "Word 513 (\"step\") appears 22 time.\n",
            "Word 517 (\"strong\") appears 10 time.\n",
            "Word 536 (\"sure\") appears 4 time.\n",
            "Word 543 (\"system\") appears 1 time.\n",
            "Word 544 (\"take\") appears 1 time.\n",
            "Word 549 (\"techniqu\") appears 6 time.\n",
            "Word 550 (\"temporarili\") appears 1 time.\n",
            "Word 554 (\"time\") appears 6 time.\n",
            "Word 559 (\"train\") appears 8 time.\n",
            "Word 570 (\"typic\") appears 10 time.\n",
            "Word 572 (\"understand\") appears 1 time.\n",
            "Word 573 (\"uniqu\") appears 1 time.\n",
            "Word 574 (\"unit\") appears 1 time.\n",
            "Word 577 (\"upper\") appears 2 time.\n",
            "Word 578 (\"use\") appears 3 time.\n",
            "Word 580 (\"valu\") appears 11 time.\n",
            "Word 581 (\"variabl\") appears 5 time.\n",
            "Word 593 (\"wide\") appears 1 time.\n",
            "Word 598 (\"work\") appears 1 time.\n",
            "Word 606 (\"addit\") appears 3 time.\n",
            "Word 608 (\"advantag\") appears 1 time.\n",
            "Word 613 (\"allow\") appears 1 time.\n",
            "Word 614 (\"amount\") appears 1 time.\n",
            "Word 615 (\"analyz\") appears 3 time.\n",
            "Word 623 (\"assumpt\") appears 16 time.\n",
            "Word 625 (\"asymptot\") appears 1 time.\n",
            "Word 626 (\"avail\") appears 1 time.\n",
            "Word 627 (\"averag\") appears 48 time.\n",
            "Word 630 (\"behavior\") appears 4 time.\n",
            "Word 631 (\"best\") appears 10 time.\n",
            "Word 650 (\"close\") appears 7 time.\n",
            "Word 652 (\"compon\") appears 2 time.\n",
            "Word 654 (\"condit\") appears 8 time.\n",
            "Word 657 (\"constant\") appears 27 time.\n",
            "Word 658 (\"constraint\") appears 1 time.\n",
            "Word 676 (\"describ\") appears 1 time.\n",
            "Word 677 (\"detail\") appears 4 time.\n",
            "Word 682 (\"earli\") appears 4 time.\n",
            "Word 695 (\"explicit\") appears 1 time.\n",
            "Word 696 (\"extend\") appears 3 time.\n",
            "Word 697 (\"extens\") appears 3 time.\n",
            "Word 704 (\"figur\") appears 9 time.\n",
            "Word 705 (\"fix\") appears 1 time.\n",
            "Word 706 (\"focus\") appears 1 time.\n",
            "Word 709 (\"general\") appears 8 time.\n",
            "Word 712 (\"help\") appears 1 time.\n",
            "Word 715 (\"import\") appears 1 time.\n",
            "Word 716 (\"independ\") appears 5 time.\n",
            "Word 723 (\"interpret\") appears 1 time.\n",
            "Word 727 (\"introduc\") appears 1 time.\n",
            "Word 732 (\"later\") appears 1 time.\n",
            "Word 734 (\"lead\") appears 4 time.\n",
            "Word 741 (\"linear\") appears 10 time.\n",
            "Word 745 (\"matrix\") appears 4 time.\n",
            "Word 761 (\"need\") appears 2 time.\n",
            "Word 771 (\"nonzero\") appears 2 time.\n",
            "Word 773 (\"normal\") appears 6 time.\n",
            "Word 774 (\"note\") appears 9 time.\n",
            "Word 782 (\"outsid\") appears 1 time.\n",
            "Word 785 (\"particular\") appears 3 time.\n",
            "Word 791 (\"potenti\") appears 1 time.\n",
            "Word 792 (\"predict\") appears 1 time.\n",
            "Word 793 (\"prefer\") appears 1 time.\n",
            "Word 794 (\"present\") appears 1 time.\n",
            "Word 795 (\"previous\") appears 2 time.\n",
            "Word 798 (\"proc\") appears 3 time.\n",
            "Word 800 (\"provid\") appears 7 time.\n",
            "Word 804 (\"quantiti\") appears 1 time.\n",
            "Word 806 (\"reach\") appears 2 time.\n",
            "Word 812 (\"relax\") appears 1 time.\n",
            "Word 813 (\"replac\") appears 4 time.\n",
            "Word 815 (\"requir\") appears 1 time.\n",
            "Word 818 (\"restrict\") appears 1 time.\n",
            "Word 823 (\"right\") appears 9 time.\n",
            "Word 826 (\"satisfi\") appears 3 time.\n",
            "Word 828 (\"scale\") appears 5 time.\n",
            "Word 833 (\"signal\") appears 2 time.\n",
            "Word 834 (\"signific\") appears 3 time.\n",
            "Word 837 (\"singer\") appears 2 time.\n",
            "Word 843 (\"stabil\") appears 1 time.\n",
            "Word 845 (\"state\") appears 1 time.\n",
            "Word 847 (\"stochast\") appears 40 time.\n",
            "Word 852 (\"studi\") appears 3 time.\n",
            "Word 853 (\"support\") appears 12 time.\n",
            "Word 856 (\"term\") appears 3 time.\n",
            "Word 857 (\"test\") appears 25 time.\n",
            "Word 858 (\"thank\") appears 1 time.\n",
            "Word 859 (\"theori\") appears 1 time.\n",
            "Word 860 (\"total\") appears 1 time.\n",
            "Word 865 (\"tune\") appears 2 time.\n",
            "Word 872 (\"vari\") appears 1 time.\n",
            "Word 873 (\"vector\") appears 1 time.\n",
            "Word 876 (\"zero\") appears 3 time.\n",
            "Word 923 (\"context\") appears 2 time.\n",
            "Word 928 (\"covari\") appears 6 time.\n",
            "Word 950 (\"exhibit\") appears 2 time.\n",
            "Word 973 (\"harri\") appears 1 time.\n",
            "Word 977 (\"higher\") appears 1 time.\n",
            "Word 987 (\"ident\") appears 3 time.\n",
            "Word 1024 (\"lower\") appears 3 time.\n",
            "Word 1037 (\"middl\") appears 3 time.\n",
            "Word 1051 (\"novel\") appears 5 time.\n",
            "Word 1055 (\"optim\") appears 27 time.\n",
            "Word 1073 (\"press\") appears 1 time.\n",
            "Word 1106 (\"smaller\") appears 4 time.\n",
            "Word 1109 (\"specif\") appears 1 time.\n",
            "Word 1111 (\"springerverlag\") appears 1 time.\n",
            "Word 1112 (\"standard\") appears 4 time.\n",
            "Word 1114 (\"statist\") appears 3 time.\n",
            "Word 1136 (\"transmiss\") appears 1 time.\n",
            "Word 1142 (\"univ\") appears 1 time.\n",
            "Word 1150 (\"weak\") appears 1 time.\n",
            "Word 1161 (\"affect\") appears 1 time.\n",
            "Word 1178 (\"cambridg\") appears 2 time.\n",
            "Word 1180 (\"chain\") appears 7 time.\n",
            "Word 1181 (\"choic\") appears 3 time.\n",
            "Word 1182 (\"choos\") appears 1 time.\n",
            "Word 1197 (\"deriv\") appears 3 time.\n",
            "Word 1198 (\"determinist\") appears 1 time.\n",
            "Word 1199 (\"deviat\") appears 1 time.\n",
            "Word 1208 (\"expect\") appears 8 time.\n",
            "Word 1224 (\"gaussian\") appears 3 time.\n",
            "Word 1229 (\"gradient\") appears 20 time.\n",
            "Word 1232 (\"high\") appears 2 time.\n",
            "Word 1243 (\"iter\") appears 15 time.\n",
            "Word 1257 (\"markov\") appears 7 time.\n",
            "Word 1270 (\"nip\") appears 2 time.\n",
            "Word 1271 (\"nois\") appears 1 time.\n",
            "Word 1272 (\"nonparametr\") appears 1 time.\n",
            "Word 1276 (\"object\") appears 1 time.\n",
            "Word 1279 (\"optimum\") appears 3 time.\n",
            "Word 1284 (\"part\") appears 1 time.\n",
            "Word 1292 (\"probabilist\") appears 1 time.\n",
            "Word 1305 (\"regress\") appears 27 time.\n",
            "Word 1306 (\"regular\") appears 1 time.\n",
            "Word 1308 (\"reli\") appears 1 time.\n",
            "Word 1311 (\"risk\") appears 5 time.\n",
            "Word 1317 (\"see\") appears 4 time.\n",
            "Word 1319 (\"sequenti\") appears 1 time.\n",
            "Word 1320 (\"set\") appears 3 time.\n",
            "Word 1324 (\"smallest\") appears 1 time.\n",
            "Word 1328 (\"springer\") appears 1 time.\n",
            "Word 1331 (\"strategi\") appears 2 time.\n",
            "Word 1339 (\"technic\") appears 4 time.\n",
            "Word 1345 (\"trivial\") appears 1 time.\n",
            "Word 1346 (\"true\") appears 3 time.\n",
            "Word 1350 (\"uniform\") appears 2 time.\n",
            "Word 1353 (\"valid\") appears 1 time.\n",
            "Word 1355 (\"variant\") appears 2 time.\n",
            "Word 1356 (\"variat\") appears 1 time.\n",
            "Word 1359 (\"volum\") appears 1 time.\n",
            "Word 1365 (\"wiley\") appears 2 time.\n",
            "Word 1371 (\"abl\") appears 1 time.\n",
            "Word 1383 (\"bias\") appears 1 time.\n",
            "Word 1385 (\"bind\") appears 9 time.\n",
            "Word 1390 (\"central\") appears 1 time.\n",
            "Word 1391 (\"certain\") appears 3 time.\n",
            "Word 1395 (\"classif\") appears 1 time.\n",
            "Word 1409 (\"crucial\") appears 1 time.\n",
            "Word 1410 (\"curv\") appears 1 time.\n",
            "Word 1411 (\"dash\") appears 2 time.\n",
            "Word 1414 (\"deal\") appears 1 time.\n",
            "Word 1418 (\"descent\") appears 7 time.\n",
            "Word 1430 (\"electron\") appears 1 time.\n",
            "Word 1434 (\"ensur\") appears 1 time.\n",
            "Word 1443 (\"get\") appears 1 time.\n",
            "Word 1445 (\"happen\") appears 1 time.\n",
            "Word 1447 (\"hold\") appears 4 time.\n",
            "Word 1451 (\"instanc\") appears 1 time.\n",
            "Word 1452 (\"interest\") appears 1 time.\n",
            "Word 1463 (\"lowest\") appears 2 time.\n",
            "Word 1472 (\"minimum\") appears 1 time.\n",
            "Word 1473 (\"mixtur\") appears 2 time.\n",
            "Word 1482 (\"overal\") appears 1 time.\n",
            "Word 1483 (\"overfit\") appears 3 time.\n",
            "Word 1485 (\"page\") appears 2 time.\n",
            "Word 1489 (\"plot\") appears 12 time.\n",
            "Word 1491 (\"predictor\") appears 2 time.\n",
            "Word 1493 (\"program\") appears 2 time.\n",
            "Word 1495 (\"quadrat\") appears 12 time.\n",
            "Word 1496 (\"quantifi\") appears 1 time.\n",
            "Word 1503 (\"say\") appears 1 time.\n",
            "Word 1505 (\"scheme\") appears 2 time.\n",
            "Word 1508 (\"setup\") appears 2 time.\n",
            "Word 1511 (\"simpli\") appears 1 time.\n",
            "Word 1512 (\"smooth\") appears 8 time.\n",
            "Word 1515 (\"speech\") appears 1 time.\n",
            "Word 1521 (\"text\") appears 1 time.\n",
            "Word 1525 (\"tradeoff\") appears 1 time.\n",
            "Word 1526 (\"transact\") appears 1 time.\n",
            "Word 1544 (\"adapt\") appears 7 time.\n",
            "Word 1597 (\"dataset\") appears 18 time.\n",
            "Word 1619 (\"explain\") appears 2 time.\n",
            "Word 1639 (\"hessian\") appears 2 time.\n",
            "Word 1654 (\"invari\") appears 3 time.\n",
            "Word 1655 (\"invert\") appears 2 time.\n",
            "Word 1664 (\"logarithm\") appears 1 time.\n",
            "Word 1665 (\"longer\") appears 1 time.\n",
            "Word 1679 (\"notabl\") appears 1 time.\n",
            "Word 1689 (\"perturb\") appears 1 time.\n",
            "Word 1707 (\"qualiti\") appears 1 time.\n",
            "Word 1710 (\"relationship\") appears 2 time.\n",
            "Word 1724 (\"sharp\") appears 1 time.\n",
            "Word 1736 (\"spline\") appears 1 time.\n",
            "Word 1740 (\"sum\") appears 1 time.\n",
            "Word 1742 (\"tabl\") appears 4 time.\n",
            "Word 1744 (\"tend\") appears 2 time.\n",
            "Word 1745 (\"theoret\") appears 10 time.\n",
            "Word 1757 (\"underli\") appears 1 time.\n",
            "Word 1762 (\"way\") appears 2 time.\n",
            "Word 1790 (\"differenti\") appears 1 time.\n",
            "Word 1795 (\"empir\") appears 1 time.\n",
            "Word 1796 (\"engin\") appears 1 time.\n",
            "Word 1799 (\"exponenti\") appears 1 time.\n",
            "Word 1808 (\"frequent\") appears 1 time.\n",
            "Word 1813 (\"highdimension\") appears 3 time.\n",
            "Word 1822 (\"journal\") appears 5 time.\n",
            "Word 1825 (\"logist\") appears 31 time.\n",
            "Word 1845 (\"preserv\") appears 3 time.\n",
            "Word 1848 (\"reason\") appears 2 time.\n",
            "Word 1857 (\"spars\") appears 4 time.\n",
            "Word 1869 (\"updat\") appears 5 time.\n",
            "Word 1912 (\"column\") appears 2 time.\n",
            "Word 1936 (\"extra\") appears 1 time.\n",
            "Word 1950 (\"greater\") appears 2 time.\n",
            "Word 1971 (\"kluwer\") appears 1 time.\n",
            "Word 1998 (\"onlin\") appears 3 time.\n",
            "Word 2013 (\"power\") appears 2 time.\n",
            "Word 2024 (\"robust\") appears 4 time.\n",
            "Word 2030 (\"sign\") appears 1 time.\n",
            "Word 2032 (\"slowest\") appears 1 time.\n",
            "Word 2037 (\"strict\") appears 1 time.\n",
            "Word 2039 (\"success\") appears 2 time.\n",
            "Word 2067 (\"year\") appears 1 time.\n",
            "Word 2068 (\"accur\") appears 1 time.\n",
            "Word 2107 (\"earlier\") appears 1 time.\n",
            "Word 2123 (\"go\") appears 2 time.\n",
            "Word 2147 (\"make\") appears 1 time.\n",
            "Word 2189 (\"radius\") appears 1 time.\n",
            "Word 2192 (\"residu\") appears 1 time.\n",
            "Word 2199 (\"sensit\") appears 1 time.\n",
            "Word 2249 (\"council\") appears 1 time.\n",
            "Word 2281 (\"issu\") appears 1 time.\n",
            "Word 2317 (\"remov\") appears 1 time.\n",
            "Word 2325 (\"scope\") appears 1 time.\n",
            "Word 2338 (\"tail\") appears 2 time.\n",
            "Word 2344 (\"ubiquit\") appears 1 time.\n",
            "Word 2370 (\"benchmark\") appears 3 time.\n",
            "Word 2375 (\"bound\") appears 5 time.\n",
            "Word 2389 (\"decay\") appears 7 time.\n",
            "Word 2416 (\"firstord\") appears 1 time.\n",
            "Word 2424 (\"goal\") appears 1 time.\n",
            "Word 2433 (\"harder\") appears 3 time.\n",
            "Word 2462 (\"loos\") appears 1 time.\n",
            "Word 2506 (\"reinforc\") appears 1 time.\n",
            "Word 2541 (\"surpris\") appears 1 time.\n",
            "Word 2560 (\"track\") appears 1 time.\n",
            "Word 2576 (\"wors\") appears 1 time.\n",
            "Word 2592 (\"classic\") appears 2 time.\n",
            "Word 2596 (\"ddimension\") appears 2 time.\n",
            "Word 2597 (\"diagon\") appears 2 time.\n",
            "Word 2635 (\"inequ\") appears 1 time.\n",
            "Word 2698 (\"proxim\") appears 1 time.\n",
            "Word 2711 (\"stationar\") appears 1 time.\n",
            "Word 2713 (\"subspac\") appears 1 time.\n",
            "Word 2963 (\"degre\") appears 2 time.\n",
            "Word 2977 (\"forget\") appears 2 time.\n",
            "Word 3015 (\"matric\") appears 1 time.\n",
            "Word 3053 (\"schmidt\") appears 1 time.\n",
            "Word 3081 (\"walk\") appears 1 time.\n",
            "Word 3122 (\"outperform\") appears 2 time.\n",
            "Word 3125 (\"practition\") appears 1 time.\n",
            "Word 3139 (\"supervis\") appears 1 time.\n",
            "Word 3217 (\"stateoftheart\") appears 1 time.\n",
            "Word 3226 (\"trick\") appears 2 time.\n",
            "Word 3271 (\"expans\") appears 1 time.\n",
            "Word 3337 (\"replic\") appears 2 time.\n",
            "Word 3345 (\"share\") appears 1 time.\n",
            "Word 3359 (\"stronger\") appears 2 time.\n",
            "Word 3391 (\"color\") appears 3 time.\n",
            "Word 3452 (\"acoust\") appears 1 time.\n",
            "Word 3474 (\"edit\") appears 1 time.\n",
            "Word 3564 (\"composit\") appears 1 time.\n",
            "Word 3576 (\"entri\") appears 1 time.\n",
            "Word 3579 (\"ergod\") appears 1 time.\n",
            "Word 3627 (\"norm\") appears 2 time.\n",
            "Word 3629 (\"novelti\") appears 1 time.\n",
            "Word 3646 (\"rat\") appears 5 time.\n",
            "Word 3722 (\"homogen\") appears 2 time.\n",
            "Word 3756 (\"proof\") appears 5 time.\n",
            "Word 3782 (\"twice\") appears 3 time.\n",
            "Word 3876 (\"onestep\") appears 2 time.\n",
            "Word 3884 (\"polynomi\") appears 1 time.\n",
            "Word 3904 (\"scenario\") appears 1 time.\n",
            "Word 3957 (\"increment\") appears 1 time.\n",
            "Word 4027 (\"tradit\") appears 1 time.\n",
            "Word 4059 (\"difficulti\") appears 1 time.\n",
            "Word 4060 (\"eigenvalu\") appears 5 time.\n",
            "Word 4091 (\"oscil\") appears 1 time.\n",
            "Word 4107 (\"son\") appears 1 time.\n",
            "Word 4110 (\"synthet\") appears 5 time.\n",
            "Word 4157 (\"doubl\") appears 2 time.\n",
            "Word 4182 (\"mention\") appears 1 time.\n",
            "Word 4250 (\"freedom\") appears 2 time.\n",
            "Word 4307 (\"barrier\") appears 1 time.\n",
            "Word 4316 (\"coincid\") appears 2 time.\n",
            "Word 4320 (\"convex\") appears 16 time.\n",
            "Word 4332 (\"eric\") appears 1 time.\n",
            "Word 4336 (\"finer\") appears 1 time.\n",
            "Word 4353 (\"largescal\") appears 2 time.\n",
            "Word 4368 (\"newton\") appears 17 time.\n",
            "Word 4377 (\"oppos\") appears 1 time.\n",
            "Word 4392 (\"siam\") appears 4 time.\n",
            "Word 4395 (\"sparsiti\") appears 2 time.\n",
            "Word 4407 (\"twostep\") appears 1 time.\n",
            "Word 4419 (\"behav\") appears 1 time.\n",
            "Word 4453 (\"inferior\") appears 2 time.\n",
            "Word 4619 (\"pari\") appears 2 time.\n",
            "Word 4715 (\"stepsiz\") appears 36 time.\n",
            "Word 4770 (\"lie\") appears 1 time.\n",
            "Word 4785 (\"moment\") appears 3 time.\n",
            "Word 4804 (\"quicker\") appears 1 time.\n",
            "Word 4844 (\"decent\") appears 1 time.\n",
            "Word 4851 (\"european\") appears 1 time.\n",
            "Word 4971 (\"notion\") appears 1 time.\n",
            "Word 4980 (\"semidefinit\") appears 1 time.\n",
            "Word 4987 (\"theorem\") appears 6 time.\n",
            "Word 5006 (\"annal\") appears 1 time.\n",
            "Word 5062 (\"underfit\") appears 1 time.\n",
            "Word 5083 (\"dedic\") appears 1 time.\n",
            "Word 5262 (\"twostag\") appears 1 time.\n",
            "Word 5441 (\"slower\") appears 1 time.\n",
            "Word 5560 (\"plain\") appears 2 time.\n",
            "Word 5596 (\"ax\") appears 1 time.\n",
            "Word 5763 (\"unregular\") appears 1 time.\n",
            "Word 5793 (\"introductori\") appears 1 time.\n",
            "Word 5827 (\"bertseka\") appears 1 time.\n",
            "Word 5871 (\"polyak\") appears 1 time.\n",
            "Word 6016 (\"telecom\") appears 1 time.\n",
            "Word 6060 (\"kurtosi\") appears 1 time.\n",
            "Word 6070 (\"outlier\") appears 1 time.\n",
            "Word 6168 (\"rescal\") appears 1 time.\n",
            "Word 6186 (\"alpha\") appears 9 time.\n",
            "Word 6340 (\"unbias\") appears 1 time.\n",
            "Word 6854 (\"ecol\") appears 1 time.\n",
            "Word 6862 (\"franc\") appears 2 time.\n",
            "Word 6869 (\"inria\") appears 1 time.\n",
            "Word 6906 (\"superieur\") appears 1 time.\n",
            "Word 6953 (\"inspir\") appears 1 time.\n",
            "Word 6962 (\"leastsquar\") appears 21 time.\n",
            "Word 7068 (\"protocol\") appears 1 time.\n",
            "Word 7174 (\"remedi\") appears 1 time.\n",
            "Word 7453 (\"bottou\") appears 1 time.\n",
            "Word 7589 (\"nonasymptot\") appears 6 time.\n",
            "Word 7669 (\"nonquadrat\") appears 1 time.\n",
            "Word 7687 (\"solver\") appears 1 time.\n",
            "Word 8119 (\"fixedpoint\") appears 1 time.\n",
            "Word 8235 (\"lighter\") appears 1 time.\n",
            "Word 8520 (\"vacuous\") appears 1 time.\n",
            "Word 8720 (\"lectur\") appears 1 time.\n",
            "Word 8876 (\"west\") appears 1 time.\n",
            "Word 9212 (\"news\") appears 9 time.\n",
            "Word 9847 (\"corollari\") appears 1 time.\n",
            "Word 10024 (\"surrog\") appears 1 time.\n",
            "Word 10553 (\"colt\") appears 2 time.\n",
            "Word 10789 (\"logn\") appears 16 time.\n",
            "Word 11676 (\"eigenvector\") appears 1 time.\n",
            "Word 12500 (\"kushner\") appears 1 time.\n",
            "Word 12506 (\"monro\") appears 1 time.\n",
            "Word 12520 (\"regret\") appears 1 time.\n",
            "Word 12522 (\"robbin\") appears 1 time.\n",
            "Word 12538 (\"aggreg\") appears 1 time.\n",
            "Word 15170 (\"highprob\") appears 2 time.\n",
            "Word 16697 (\"hyvarinen\") appears 1 time.\n",
            "Word 17408 (\"meyn\") appears 1 time.\n",
            "Word 17424 (\"tweedi\") appears 1 time.\n",
            "Word 18343 (\"worsen\") appears 1 time.\n",
            "Word 18768 (\"borkar\") appears 1 time.\n",
            "Word 19121 (\"primal\") appears 1 time.\n",
            "Word 19566 (\"cramerrao\") appears 1 time.\n",
            "Word 19719 (\"errat\") appears 1 time.\n",
            "Word 20274 (\"franci\") appears 2 time.\n",
            "Word 20316 (\"quantum\") appears 2 time.\n",
            "Word 20575 (\"bach\") appears 7 time.\n",
            "Word 20859 (\"nonsmooth\") appears 1 time.\n",
            "Word 20928 (\"priouret\") appears 1 time.\n",
            "Word 21206 (\"anova\") appears 1 time.\n",
            "Word 22700 (\"shapiro\") appears 1 time.\n",
            "Word 22757 (\"moulin\") appears 4 time.\n",
            "Word 23458 (\"pointwis\") appears 3 time.\n",
            "Word 25312 (\"icml\") appears 1 time.\n",
            "Word 27425 (\"leastmeansquar\") appears 3 time.\n",
            "Word 28562 (\"mestim\") appears 1 time.\n",
            "Word 28672 (\"gyorfi\") appears 1 time.\n",
            "Word 29171 (\"lowerbound\") appears 2 time.\n",
            "Word 29328 (\"sussex\") appears 1 time.\n",
            "Word 29393 (\"kale\") appears 1 time.\n",
            "Word 30735 (\"logscal\") appears 1 time.\n",
            "Word 30972 (\"nicola\") appears 1 time.\n",
            "Word 33657 (\"dyadic\") appears 1 time.\n",
            "Word 34355 (\"homoscedast\") appears 1 time.\n",
            "Word 34415 (\"juditski\") appears 2 time.\n",
            "Word 35701 (\"macchi\") appears 1 time.\n",
            "Word 36750 (\"nonspars\") appears 4 time.\n",
            "Word 36856 (\"copt\") appears 8 time.\n",
            "Word 38267 (\"limn\") appears 3 time.\n",
            "Word 38650 (\"fastica\") appears 1 time.\n",
            "Word 41541 (\"vaart\") appears 1 time.\n",
            "Word 43712 (\"logff\") appears 11 time.\n",
            "Word 45644 (\"covertyp\") appears 8 time.\n",
            "Word 46144 (\"twotimescal\") appears 1 time.\n",
            "Word 49104 (\"bousquet\") appears 1 time.\n",
            "Word 50916 (\"subgradi\") appears 3 time.\n",
            "Word 56529 (\"nemirovski\") appears 2 time.\n",
            "Word 56530 (\"nesterov\") appears 1 time.\n",
            "Word 56902 (\"parametertun\") appears 1 time.\n",
            "Word 57246 (\"rankon\") appears 1 time.\n",
            "Word 57312 (\"rthe\") appears 1 time.\n",
            "Word 57884 (\"srebro\") appears 1 time.\n",
            "Word 62410 (\"selfadjoint\") appears 1 time.\n",
            "Word 62469 (\"tsybakov\") appears 1 time.\n",
            "Word 68030 (\"shalevshwartz\") appears 1 time.\n",
            "Word 70053 (\"selfconcord\") appears 4 time.\n",
            "Word 70753 (\"roux\") appears 1 time.\n",
            "Word 72396 (\"sierra\") appears 2 time.\n",
            "Word 73811 (\"hazan\") appears 2 time.\n",
            "Word 74170 (\"almostsur\") appears 1 time.\n",
            "Word 78199 (\"constants\") appears 1 time.\n",
            "Word 78727 (\"paristech\") appears 1 time.\n",
            "Word 79177 (\"yudin\") appears 1 time.\n",
            "Word 79516 (\"supn\") appears 1 time.\n",
            "Word 79546 (\"nedic\") appears 1 time.\n",
            "Word 81934 (\"newtontyp\") appears 1 time.\n",
            "Word 83851 (\"wellspecifi\") appears 2 time.\n",
            "Word 88020 (\"duchi\") appears 1 time.\n",
            "Word 88880 (\"runningtim\") appears 2 time.\n",
            "Word 89357 (\"ltci\") appears 1 time.\n",
            "Word 89884 (\"pegaso\") appears 1 time.\n",
            "Word 91192 (\"nonaverag\") appears 2 time.\n",
            "Word 91194 (\"projectteam\") appears 1 time.\n",
            "Word 92761 (\"newtonstep\") appears 1 time.\n",
            "Word 93351 (\"pathwis\") appears 1 time.\n",
            "Word 97857 (\"nonstrong\") appears 1 time.\n",
            "Word 101092 (\"unimprov\") appears 1 time.\n",
            "Word 103252 (\"newtonbas\") appears 2 time.\n",
            "Word 113135 (\"adagrad\") appears 12 time.\n",
            "Word 121602 (\"ekxn\") appears 1 time.\n",
            "Word 121608 (\"stronglyconvex\") appears 2 time.\n",
            "Word 130760 (\"strongconvex\") appears 2 time.\n",
            "Word 137784 (\"aguech\") appears 1 time.\n",
            "Word 137785 (\"aymer\") appears 1 time.\n",
            "Word 137786 (\"bershad\") appears 1 time.\n",
            "Word 137787 (\"constantstep\") appears 1 time.\n",
            "Word 137788 (\"dblapprox\") appears 1 time.\n",
            "Word 137789 (\"dieuleveut\") appears 1 time.\n",
            "Word 137790 (\"ekzn\") appears 1 time.\n",
            "Word 137791 (\"flammarion\") appears 1 time.\n",
            "Word 137792 (\"harrisrecurr\") appears 1 time.\n",
            "Word 137793 (\"nminh\") appears 1 time.\n",
            "Word 137794 (\"noiseratio\") appears 1 time.\n",
            "Word 137795 (\"nonsharp\") appears 1 time.\n",
            "Word 137796 (\"onconverg\") appears 1 time.\n",
            "Word 137797 (\"onlylead\") appears 1 time.\n",
            "Word 137798 (\"sido\") appears 10 time.\n",
            "Word 137799 (\"stepdbl\") appears 2 time.\n",
            "Word 137800 (\"withr\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF VECTORIZER"
      ],
      "metadata": {
        "id": "aefacjXJz5-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ],
      "metadata": {
        "id": "UWeY-zjQwj3P"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "metadata": {
        "id": "_GCcW8Z6xBKg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwm3tHGuxCwY",
        "outputId": "1d7c469d-8c09-48f7-e1ab-d70ef3938357"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.039611586240012917),\n",
            " (1, 5.495865573345913e-05),\n",
            " (2, 0.01382394931037369),\n",
            " (3, 0.026609881107965784),\n",
            " (4, 0.01571179534491862),\n",
            " (5, 0.022405615520321342),\n",
            " (6, 0.005335292542489926),\n",
            " (7, 0.01746013017837683),\n",
            " (8, 0.04228971422979104),\n",
            " (9, 0.01179065669951928),\n",
            " (10, 0.014220220342586557),\n",
            " (11, 0.04496784221956916),\n",
            " (12, 0.010788313918834521),\n",
            " (13, 0.007032687098925953),\n",
            " (14, 0.00749870326644307),\n",
            " (15, 0.05870271233419937),\n",
            " (16, 0.008636082988664908),\n",
            " (17, 0.011409908662184672),\n",
            " (18, 0.021006813389680013),\n",
            " (19, 0.008638355121415846),\n",
            " (20, 0.0016352381716152734),\n",
            " (21, 0.01406498226089948),\n",
            " (22, 0.022698187249499024),\n",
            " (23, 0.02430664624564325),\n",
            " (24, 0.0541244222959893),\n",
            " (25, 0.0045174551708301765),\n",
            " (26, 0.009476344774453315),\n",
            " (27, 0.0028498953276625953),\n",
            " (28, 0.005848727584303654),\n",
            " (29, 0.0015551052736772627),\n",
            " (30, 0.0062804661728952625),\n",
            " (31, 0.012399067326351236),\n",
            " (32, 0.016535514490932757),\n",
            " (33, 0.05272467451436376),\n",
            " (34, 0.04418987627822299),\n",
            " (35, 0.00854789615694149),\n",
            " (36, 0.016107305617129506),\n",
            " (37, 0.014126640364035556),\n",
            " (38, 0.011974538894269908),\n",
            " (39, 0.009212458595163772),\n",
            " (40, 0.0064988555291497965),\n",
            " (41, 0.05127378885600848),\n",
            " (42, 0.0070279652925645435),\n",
            " (43, 0.02367397859464457),\n",
            " (44, 0.04251979387761265),\n",
            " (45, 0.01428853121049942),\n",
            " (46, 0.06480816561490262),\n",
            " (47, 0.008416119689720815),\n",
            " (48, 0.09733713886839547),\n",
            " (49, 0.027377845901030335),\n",
            " (50, 0.012685362568041314),\n",
            " (51, 0.011916394898177514),\n",
            " (52, 0.0032742734056269043),\n",
            " (53, 0.009926797057374691),\n",
            " (54, 0.008454764677453494),\n",
            " (55, 0.018581084647822127),\n",
            " (56, 0.10362021793091306),\n",
            " (57, 0.0541244222959893),\n",
            " (58, 0.06624387971002843),\n",
            " (59, 0.020319682488666415),\n",
            " (60, 0.01821986784258454),\n",
            " (61, 0.028351594960746913),\n",
            " (62, 0.041761026035637125),\n",
            " (63, 0.05870271233419937),\n",
            " (64, 0.01818663542481214),\n",
            " (65, 0.006245151119952927),\n",
            " (66, 0.02052046014582647),\n",
            " (67, 0.004935306809597392),\n",
            " (68, 0.2180700048706287),\n",
            " (69, 0.047843494779080314),\n",
            " (70, 0.014517398518224433),\n",
            " (71, 0.025390504452755158),\n",
            " (72, 0.004229547257206087),\n",
            " (73, 0.02601577550022274),\n",
            " (74, 0.011806490926012598),\n",
            " (75, 0.006259254491148744),\n",
            " (76, 0.012910403548926508),\n",
            " (77, 0.017828755427046383),\n",
            " (78, 0.05068326774325454),\n",
            " (79, 0.01297812099875373),\n",
            " (80, 0.02326003114922687),\n",
            " (81, 0.015155149913537981),\n",
            " (82, 0.022233041497200606),\n",
            " (83, 0.003425322722489544),\n",
            " (84, 0.007241839291024979),\n",
            " (85, 0.026706486852559098),\n",
            " (86, 0.028503421270106973),\n",
            " (87, 0.01770874439641724),\n",
            " (88, 0.006103450712267664),\n",
            " (89, 0.054052299398494444),\n",
            " (90, 0.004976818989925416),\n",
            " (91, 0.014798681460485429),\n",
            " (92, 0.05862623325177687),\n",
            " (93, 0.0012792885709810432),\n",
            " (94, 0.002652636278281376),\n",
            " (95, 0.024857882165985255),\n",
            " (96, 0.05532539982760066),\n",
            " (97, 0.04081583403994828),\n",
            " (98, 0.002721255247755646),\n",
            " (99, 0.019796318665053877),\n",
            " (100, 0.003119935095428922),\n",
            " (101, 0.0457938864696498),\n",
            " (102, 0.012136114924636862),\n",
            " (103, 0.004645216916932403),\n",
            " (104, 0.007624034530247995),\n",
            " (105, 0.0030276400440751535),\n",
            " (106, 0.016478231156647764),\n",
            " (107, 0.0017912987830385446),\n",
            " (108, 0.04228971422979104),\n",
            " (109, 0.022987856032241582),\n",
            " (110, 0.008674724600939404),\n",
            " (111, 0.0209196163961318),\n",
            " (112, 0.12244750211984484),\n",
            " (113, 0.004441967762518487),\n",
            " (114, 0.015798685062277676),\n",
            " (115, 0.01889230905798003),\n",
            " (116, 0.006694484085614426),\n",
            " (117, 0.001085103885900409),\n",
            " (118, 0.02218474042469581),\n",
            " (119, 0.048091435623778316),\n",
            " (120, 0.01175762454035616),\n",
            " (121, 0.010302162520026114),\n",
            " (122, 0.02043186628955359),\n",
            " (123, 0.030596464615459187),\n",
            " (124, 0.011153221967122045),\n",
            " (125, 0.003659237972185515),\n",
            " (126, 0.03247863117741298),\n",
            " (127, 0.026758701166636582),\n",
            " (128, 0.006370430542198524),\n",
            " (129, 0.2053334787192457),\n",
            " (130, 0.011303003358895287),\n",
            " (131, 0.011495568507502083),\n",
            " (132, 0.06546540779712184),\n",
            " (133, 0.023695119860631896),\n",
            " (134, 0.029358661660286212),\n",
            " (135, 0.03294511471357035),\n",
            " (136, 0.0035929023581782998),\n",
            " (137, 0.006503759019505475),\n",
            " (138, 0.004592726152581089),\n",
            " (139, 0.04153947578603746),\n",
            " (140, 0.0184265129618833),\n",
            " (141, 0.01254677608153055),\n",
            " (142, 0.007925931963798915),\n",
            " (143, 0.003106781935422392),\n",
            " (144, 0.006728639011638492),\n",
            " (145, 0.00028900653819010795),\n",
            " (146, 0.0057739689315875475),\n",
            " (147, 0.015356541587179275),\n",
            " (148, 0.004486053654092674),\n",
            " (149, 0.028351594960746913),\n",
            " (150, 0.006320719496145489),\n",
            " (151, 0.0055107523460669995),\n",
            " (152, 0.012298495479434297),\n",
            " (153, 0.02041930845483459),\n",
            " (154, 0.1082488445919786),\n",
            " (155, 0.011499924699682616),\n",
            " (156, 0.020984905985404735),\n",
            " (157, 0.010992292988526265),\n",
            " (158, 0.004861542997481808),\n",
            " (159, 0.009175763632261991),\n",
            " (160, 0.038586039454727314),\n",
            " (161, 0.026603280435068155),\n",
            " (162, 0.02708096392531807),\n",
            " (163, 0.011356923454796332),\n",
            " (164, 0.05870271233419937),\n",
            " (165, 0.007478107480269112),\n",
            " (166, 0.005691404402343911),\n",
            " (167, 0.0362397944225779),\n",
            " (168, 0.002142637053461252),\n",
            " (169, 0.005630920551685806),\n",
            " (170, 0.050035410571687734),\n",
            " (171, 0.015679916054953256),\n",
            " (172, 0.020643923111214716),\n",
            " (173, 0.007862638482435659),\n",
            " (174, 0.04038955218135909),\n",
            " (175, 0.06020242698303605),\n",
            " (176, 0.022227694653837508),\n",
            " (177, 0.009911623653227744),\n",
            " (178, 0.004390344480281931),\n",
            " (179, 0.004146651310433568),\n",
            " (180, 0.01928343759230705),\n",
            " (181, 0.00886483706916013),\n",
            " (182, 0.007090674428221118),\n",
            " (183, 0.051911174638136034),\n",
            " (184, 0.018321006197908378),\n",
            " (185, 0.11740542466839873),\n",
            " (186, 0.024260777613907353),\n",
            " (187, 0.007899342531138838),\n",
            " (188, 0.005377171144507105),\n",
            " (189, 0.016170311592503962),\n",
            " (190, 0.056138034879785255),\n",
            " (191, 0.018759357472234547),\n",
            " (192, 0.0369334582502348),\n",
            " (193, 0.007900745554726142),\n",
            " (194, 0.00707919767900436),\n",
            " (195, 0.017760723665927694),\n",
            " (196, 0.014251710635053486),\n",
            " (197, 0.0047025963912357945),\n",
            " (198, 0.1082488445919786),\n",
            " (199, 0.01085403661366703),\n",
            " (200, 0.0032172003599815185),\n",
            " (201, 0.0035428043596079837),\n",
            " (202, 0.016024221800465983),\n",
            " (203, 0.02367397859464457),\n",
            " (204, 0.012286763546804816),\n",
            " (205, 0.006050802103699427),\n",
            " (206, 0.008197962321618912),\n",
            " (207, 0.00323057547693913),\n",
            " (208, 0.01718929226809275),\n",
            " (209, 0.0022623159589729427),\n",
            " (210, 0.03304789171780536),\n",
            " (211, 0.04496784221956916),\n",
            " (212, 0.05870271233419937),\n",
            " (213, 0.005047862328275162),\n",
            " (214, 0.004034801303660417),\n",
            " (215, 0.013861035743202028),\n",
            " (216, 0.03370785094030316),\n",
            " (217, 0.013794429367007057),\n",
            " (218, 0.004033133032298087),\n",
            " (219, 0.02142798882737617),\n",
            " (220, 0.029354502493632757),\n",
            " (221, 0.00032819457437777095),\n",
            " (222, 0.01962876653000413),\n",
            " (223, 0.011050192166721777),\n",
            " (224, 0.028154413860350853),\n",
            " (225, 0.03436643017072576),\n",
            " (226, 0.002053657352885111),\n",
            " (227, 0.0009585470276046933),\n",
            " (228, 0.019747022630347028),\n",
            " (229, 0.0037567847533180715),\n",
            " (230, 0.03503329620180285),\n",
            " (231, 0.01665168904956107),\n",
            " (232, 0.008857858646605155),\n",
            " (233, 0.005747784253751042),\n",
            " (234, 0.024585253816676866),\n",
            " (235, 0.010643821466944018),\n",
            " (236, 0.05870271233419937),\n",
            " (237, 0.03364831029774054),\n",
            " (238, 0.008475093977343926),\n",
            " (239, 0.0559068160485457),\n",
            " (240, 0.03593159024287319),\n",
            " (241, 0.03612688644747592),\n",
            " (242, 0.043493962029726406),\n",
            " (243, 0.02146499208033221),\n",
            " (244, 0.02451384823497215),\n",
            " (245, 0.038593409232834844),\n",
            " (246, 0.022502673887108002),\n",
            " (247, 0.013743084817133815),\n",
            " (248, 0.02244785966103715),\n",
            " (249, 0.008416119689720815),\n",
            " (250, 0.01090613859746953),\n",
            " (251, 0.11295121240646629),\n",
            " (252, 0.020023223550894524),\n",
            " (253, 0.022929245534001542),\n",
            " (254, 0.05870271233419937),\n",
            " (255, 0.05870271233419937),\n",
            " (256, 0.05870271233419937),\n",
            " (257, 0.05870271233419937),\n",
            " (258, 0.05870271233419937),\n",
            " (259, 0.12644895458454813),\n",
            " (260, 0.02329096833147182),\n",
            " (261, 0.003524115142704402),\n",
            " (262, 0.005671999887977961),\n",
            " (263, 0.020682672138903468),\n",
            " (264, 0.01048699350492732),\n",
            " (265, 0.009953637979850832),\n",
            " (266, 0.0018152693277062502),\n",
            " (267, 0.015741392450456342),\n",
            " (268, 0.03113153415172058),\n",
            " (269, 0.0162880872245799),\n",
            " (270, 0.02681133153541068),\n",
            " (271, 0.030725051886961643),\n",
            " (272, 0.002102647246512215),\n",
            " (273, 0.00858939095497975),\n",
            " (274, 0.002351566365599927),\n",
            " (275, 0.018424466210839097),\n",
            " (276, 0.04418987627822299),\n",
            " (277, 0.014411454245219104),\n",
            " (278, 0.00666201269922369),\n",
            " (279, 0.0069298564038099975),\n",
            " (280, 0.01989834640068185),\n",
            " (281, 0.01186121432382548),\n",
            " (282, 0.0166403498599369),\n",
            " (283, 0.022958377069772686),\n",
            " (284, 0.008057456699653468),\n",
            " (285, 0.01873015266863942),\n",
            " (286, 0.00041601264736669606),\n",
            " (287, 0.006664392569631927),\n",
            " (288, 0.11740542466839873),\n",
            " (289, 0.02129842608717264),\n",
            " (290, 0.039611586240012917),\n",
            " (291, 0.021555647402771373),\n",
            " (292, 0.11740542466839873),\n",
            " (293, 0.021483532648523426),\n",
            " (294, 0.004070022446127548),\n",
            " (295, 0.009878318578682831),\n",
            " (296, 0.031770266262960346),\n",
            " (297, 0.0541244222959893),\n",
            " (298, 0.005926579191657415),\n",
            " (299, 0.012574246513905114),\n",
            " (300, 0.011217710644887184),\n",
            " (301, 0.02474163206038575),\n",
            " (302, 0.07410935515990862),\n",
            " (303, 0.001085103885900409),\n",
            " (304, 0.02052046014582647),\n",
            " (305, 0.013181937372299089),\n",
            " (306, 0.006357425161650556),\n",
            " (307, 0.00721459058763568),\n",
            " (308, 0.16704008582713675),\n",
            " (309, 0.018382576745545894),\n",
            " (310, 0.005022100331842587),\n",
            " (311, 0.006800897283316971),\n",
            " (312, 0.002963799954002691),\n",
            " (313, 0.013644769710400325),\n",
            " (314, 0.05870271233419937),\n",
            " (315, 0.007233034486608017),\n",
            " (316, 0.007304941227114403),\n",
            " (317, 0.01810573841415468),\n",
            " (318, 0.0053958259431381205),\n",
            " (319, 0.013861035743202028),\n",
            " (320, 0.03623754400173821),\n",
            " (321, 0.006014422933820308),\n",
            " (322, 0.05903186562493471),\n",
            " (323, 0.017896919874468974),\n",
            " (324, 0.024673794793919998),\n",
            " (325, 0.05870271233419937),\n",
            " (326, 0.003971270075493936),\n",
            " (327, 0.01714913979746025),\n",
            " (328, 0.029266850854573503),\n",
            " (329, 0.02118982003162895),\n",
            " (330, 0.011353694907274196),\n",
            " (331, 0.012179351565399343),\n",
            " (332, 0.00588420307117542),\n",
            " (333, 0.004551889725524208),\n",
            " (334, 0.005894608597747725),\n",
            " (335, 0.01259926476593909),\n",
            " (336, 0.026864384642597917),\n",
            " (337, 0.02702863190446263),\n",
            " (338, 0.00857813116432879),\n",
            " (339, 0.027588858734014114),\n",
            " (340, 0.0029310203515689782),\n",
            " (341, 0.11420735005976898),\n",
            " (342, 0.01258650083343848),\n",
            " (343, 0.0011784893299442607),\n",
            " (344, 0.06945427775783365),\n",
            " (345, 0.05320656087013631),\n",
            " (346, 0.020219411522691123),\n",
            " (347, 0.06405563769257065),\n",
            " (348, 0.059354080444493224),\n",
            " (349, 0.006052966596061079),\n",
            " (350, 0.042369477324088606),\n",
            " (351, 0.007621142007174013),\n",
            " (352, 0.006664392569631927),\n",
            " (353, 0.010398333431002348),\n",
            " (354, 0.00629701137186218),\n",
            " (355, 0.03434185313541758),\n",
            " (356, 0.02067868543617905),\n",
            " (357, 0.012477928179611597),\n",
            " (358, 0.057828027318579944),\n",
            " (359, 0.010469166027616503),\n",
            " (360, 0.02322923819679345),\n",
            " (361, 0.012537346992859168),\n",
            " (362, 0.009532881755912782),\n",
            " (363, 0.05870271233419937),\n",
            " (364, 0.005783384002252668),\n",
            " (365, 0.018994409481095348),\n",
            " (366, 0.1613320493959081),\n",
            " (367, 0.004088546660228081),\n",
            " (368, 0.04286443101672329),\n",
            " (369, 0.05870271233419937),\n",
            " (370, 0.007880660529998173),\n",
            " (371, 0.049780325730753035),\n",
            " (372, 0.0014304667064201028),\n",
            " (373, 0.05527339863251728),\n",
            " (374, 0.01258650083343848),\n",
            " (375, 0.07718681846566969),\n",
            " (376, 0.0034822567556910457),\n",
            " (377, 0.004715622324274853),\n",
            " (378, 0.020643923111214716),\n",
            " (379, 0.04584982726082303),\n",
            " (380, 0.002170207771800818),\n",
            " (381, 0.008702762329395038),\n",
            " (382, 0.04584982726082303),\n",
            " (383, 0.00892219155558888),\n",
            " (384, 0.0069742824061804105),\n",
            " (385, 0.009227193852438247),\n",
            " (386, 0.031659253963528144),\n",
            " (387, 0.16237326688796788),\n",
            " (388, 0.03464985258649085),\n",
            " (389, 0.004333845220336612),\n",
            " (390, 0.01490654242626145),\n",
            " (391, 0.0012946849311915808),\n",
            " (392, 0.023700466626519735),\n",
            " (393, 0.009833164207009035),\n",
            " (394, 0.01524806906049599),\n",
            " (395, 0.009669476090106969),\n",
            " (396, 0.03925446811636213),\n",
            " (397, 0.01809535795350692),\n",
            " (398, 0.02869390349000086),\n",
            " (399, 0.04034770420213998),\n",
            " (400, 0.005174787324541424),\n",
            " (401, 0.009754305595400097),\n",
            " (402, 0.01856012723814603),\n",
            " (403, 0.09614450413587293),\n",
            " (404, 0.018035396148330135),\n",
            " (405, 0.02665097026292111),\n",
            " (406, 0.011927486548699809),\n",
            " (407, 0.0068470330448185375),\n",
            " (408, 0.02697178662418462),\n",
            " (409, 0.0019523618835194348),\n",
            " (410, 0.003890091880646089),\n",
            " (411, 0.004367333337527396),\n",
            " (412, 0.003397801531281805),\n",
            " (413, 0.004222550883683295),\n",
            " (414, 0.013952244104734052),\n",
            " (415, 0.005926579191657415),\n",
            " (416, 0.012037918775049295),\n",
            " (417, 0.04566017122601484),\n",
            " (418, 0.002652636278281376),\n",
            " (419, 0.008110185929056402),\n",
            " (420, 0.014123588724142516),\n",
            " (421, 0.012187874603530841),\n",
            " (422, 0.0339003759093757),\n",
            " (423, 0.010672554272871884),\n",
            " (424, 0.004018035731121508),\n",
            " (425, 0.015209662544835427),\n",
            " (426, 0.03724300892346299),\n",
            " (427, 0.008380337361542653),\n",
            " (428, 0.055030856026311435),\n",
            " (429, 0.005018634387497042),\n",
            " (430, 0.029233449692233408),\n",
            " (431, 0.04397691209683153),\n",
            " (432, 0.0541244222959893),\n",
            " (433, 0.0025727051410643405),\n",
            " (434, 0.09116681736404461),\n",
            " (435, 0.06978964326971004),\n",
            " (436, 0.021548630329482756),\n",
            " (437, 0.06091051728696795),\n",
            " (438, 0.05870271233419937),\n",
            " (439, 0.006059702535545491),\n",
            " (440, 6.877007012089273e-05),\n",
            " (441, 0.02686870182723313),\n",
            " (442, 0.0970272502024142),\n",
            " (443, 0.016965445591569338),\n",
            " (444, 0.006100067895804207),\n",
            " (445, 0.007803484628385938),\n",
            " (446, 0.013184464838756191),\n",
            " (447, 0.006936725403902867),\n",
            " (448, 0.0037567847533180715),\n",
            " (449, 0.013634386648156383),\n",
            " (450, 0.0033102624651380635),\n",
            " (451, 0.06368993726331343),\n",
            " (452, 0.004230325734946269),\n",
            " (453, 0.0074021377136992365),\n",
            " (454, 0.009161142538668189),\n",
            " (455, 8.538197967500124e-05),\n",
            " (456, 0.008435719337140634),\n",
            " (457, 0.05870271233419937),\n",
            " (458, 0.02500238846750682),\n",
            " (459, 0.05870271233419937),\n",
            " (460, 0.05144629430621118),\n",
            " (461, 0.11740542466839873),\n",
            " (462, 0.4161672589179639),\n",
            " (463, 0.016930456580343207),\n",
            " (464, 0.01269159083472994),\n",
            " (465, 0.009482857635450285),\n",
            " (466, 0.12336815149182652),\n",
            " (467, 0.0372181247698229),\n",
            " (468, 0.019381085677084058),\n",
            " (469, 0.006249848898482311),\n",
            " (470, 0.04348510956582232),\n",
            " (471, 0.05567664237487388),\n",
            " (472, 0.07644855825810032),\n",
            " (473, 0.030363900218010945),\n",
            " (474, 0.002212398469761054),\n",
            " (475, 0.02519751343427483),\n",
            " (476, 0.0036100070566405656),\n",
            " (477, 0.004520401433540027),\n",
            " (478, 0.002629505901841669),\n",
            " (479, 0.024476636438891922),\n",
            " (480, 0.07063147528800333),\n",
            " (481, 0.02869390349000086),\n",
            " (482, 0.013328785139263853),\n",
            " (483, 0.019154677702047828),\n",
            " (484, 0.01115816034218116),\n",
            " (485, 0.001485841376206747),\n",
            " (486, 0.003415071604272846),\n",
            " (487, 0.0018986419277527864),\n",
            " (488, 0.013605700060897768),\n",
            " (489, 0.002304850503273103),\n",
            " (490, 0.008798837860896266),\n",
            " (491, 0.002371129247905131),\n",
            " (492, 0.06803023838924956),\n",
            " (493, 0.006979528694251204),\n",
            " (494, 0.04286443101672329),\n",
            " (495, 0.0159625876705018),\n",
            " (496, 0.00502172700928521),\n",
            " (497, 0.03718273599742706),\n",
            " (498, 0.006631838742140003),\n",
            " (499, 0.0036735398391963643),\n",
            " (500, 0.008843923881238634),\n",
            " (501, 0.0035252969766821833),\n",
            " (502, 0.01520054580586717),\n",
            " (503, 0.05870271233419937),\n",
            " (504, 0.018140973520312968),\n",
            " (505, 0.017061346751182677),\n",
            " (506, 0.029358661660286212),\n",
            " (507, 0.00535671208398855),\n",
            " (508, 0.03684271615677759),\n",
            " (509, 0.016055255888884457),\n",
            " (510, 0.004449119984477629),\n",
            " (511, 0.01356290244031802),\n",
            " (512, 0.048072252067936465),\n",
            " (513, 0.01432878444466171),\n",
            " (514, 0.05061164565405671),\n",
            " (515, 0.04686800426800111),\n",
            " (516, 0.023591200886385513),\n",
            " (517, 0.005706536313507142),\n",
            " (518, 0.03172934967732798),\n",
            " (519, 0.05783682985772169),\n",
            " (520, 0.02411561345179079),\n",
            " (521, 0.039705458295393105),\n",
            " (522, 0.009387709399300108),\n",
            " (523, 0.0054165055978949266),\n",
            " (524, 0.013096306432205364),\n",
            " (525, 0.018439325781412098),\n",
            " (526, 0.04286443101672329),\n",
            " (527, 0.014363124202754322),\n",
            " (528, 0.005047951241369777),\n",
            " (529, 0.011769554125311369),\n",
            " (530, 0.05870271233419937),\n",
            " (531, 0.009556098216841611),\n",
            " (532, 0.031843630929802524),\n",
            " (533, 0.02377330492253684),\n",
            " (534, 0.011639673614287948),\n",
            " (535, 0.03081046138952984),\n",
            " (536, 0.016308921993661064),\n",
            " (537, 0.019519780039830723),\n",
            " (538, 0.0141654710245727),\n",
            " (539, 0.029129560902093083),\n",
            " (540, 0.01457515720525062),\n",
            " (541, 0.0262542518119189),\n",
            " (542, 0.018306777995626612),\n",
            " (543, 0.006289771835383005),\n",
            " (544, 0.001989241244175429),\n",
            " (545, 0.02890814096226079),\n",
            " (546, 0.009835056017776537),\n",
            " (547, 0.0977585324534043),\n",
            " (548, 0.022102243632298027),\n",
            " (549, 0.003545924376828907),\n",
            " (550, 0.028764546691029867),\n",
            " (551, 0.02143748546201267),\n",
            " (552, 0.0369334582502348),\n",
            " (553, 0.013905816093260248),\n",
            " (554, 0.007964845881089071),\n",
            " (555, 0.031659253963528144),\n",
            " (556, 0.01284285873602395),\n",
            " (557, 0.05870271233419937),\n",
            " (558, 0.012997672299661273),\n",
            " (559, 0.01122275367420931),\n",
            " (560, 0.013634386648156383),\n",
            " (561, 0.010778978120341943),\n",
            " (562, 0.049388897841684806),\n",
            " (563, 0.033121939855014215),\n",
            " (564, 0.025607083735475312),\n",
            " (565, 0.0541244222959893),\n",
            " (566, 0.015556145695668298),\n",
            " (567, 0.02655227573116416),\n",
            " (568, 0.0126509426996561),\n",
            " (569, 0.061539326073223134),\n",
            " (570, 0.007652846649350628),\n",
            " (571, 0.04686800426800111),\n",
            " (572, 0.0060988558763718425),\n",
            " (573, 0.007989837831131623),\n",
            " (574, 0.009793810189666867),\n",
            " (575, 0.0038877488365472216),\n",
            " (576, 0.014186687370423865),\n",
            " (577, 0.006679421191209732),\n",
            " (578, 0.00422233852972324),\n",
            " (579, 0.011249610495297803),\n",
            " (580, 0.003697359790133616),\n",
            " (581, 0.0022777513926784255),\n",
            " (582, 0.04858731726881301),\n",
            " (583, 0.004413436070922473),\n",
            " (584, 0.021018691460869095),\n",
            " (585, 0.025695743809400286),\n",
            " (586, 0.015137078557986365),\n",
            " (587, 0.016741224188036),\n",
            " (588, 0.014218763839444525),\n",
            " (589, 0.02197398569295409),\n",
            " (590, 0.010737129555848145),\n",
            " (591, 0.002614582235295171),\n",
            " (592, 0.03885642689185174),\n",
            " (593, 0.006337365961963636),\n",
            " (594, 0.03260444595921699),\n",
            " (595, 0.02694222952166019),\n",
            " (596, 0.1467313881422041),\n",
            " (597, 0.033762727582505925),\n",
            " (598, 0.0007712420568212603),\n",
            " (599, 0.028370765660578272),\n",
            " (600, 0.04954613225777923),\n",
            " (601, 0.0541244222959893),\n",
            " (602, 0.05870271233419937),\n",
            " (603, 0.0541244222959893)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS"
      ],
      "metadata": {
        "id": "SNQH4JwO0CeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA with Bag of Words corpus"
      ],
      "metadata": {
        "id": "CaTVjPey0FVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "metadata": {
        "id": "_bSxujlKxETa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLSydGslxoS3",
        "outputId": "e3defe1c-b0b2-4489-e22f-3eb1bfb30f7f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.014*\"model\" + 0.011*\"imag\" + 0.007*\"train\" + 0.007*\"network\" + 0.006*\"data\" + 0.005*\"time\" + 0.005*\"figur\" + 0.005*\"function\" + 0.005*\"learn\" + 0.005*\"neural\"\n",
            "Topic: 1 \n",
            "Words: 0.012*\"learn\" + 0.010*\"model\" + 0.010*\"algorithm\" + 0.008*\"function\" + 0.006*\"data\" + 0.006*\"method\" + 0.006*\"valu\" + 0.006*\"state\" + 0.005*\"approxim\" + 0.005*\"perform\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"learn\" + 0.009*\"model\" + 0.009*\"function\" + 0.007*\"algorithm\" + 0.006*\"problem\" + 0.006*\"method\" + 0.006*\"data\" + 0.006*\"optim\" + 0.006*\"network\" + 0.006*\"result\"\n",
            "Topic: 3 \n",
            "Words: 0.016*\"model\" + 0.008*\"learn\" + 0.007*\"data\" + 0.006*\"algorithm\" + 0.006*\"train\" + 0.006*\"featur\" + 0.006*\"distribut\" + 0.006*\"estim\" + 0.006*\"network\" + 0.006*\"function\"\n",
            "Topic: 4 \n",
            "Words: 0.009*\"function\" + 0.008*\"model\" + 0.007*\"algorithm\" + 0.007*\"learn\" + 0.007*\"neuron\" + 0.006*\"comput\" + 0.006*\"time\" + 0.006*\"result\" + 0.006*\"network\" + 0.005*\"optim\"\n",
            "Topic: 5 \n",
            "Words: 0.016*\"algorithm\" + 0.010*\"problem\" + 0.008*\"function\" + 0.008*\"learn\" + 0.008*\"data\" + 0.007*\"optim\" + 0.006*\"result\" + 0.005*\"comput\" + 0.005*\"model\" + 0.005*\"give\"\n",
            "Topic: 6 \n",
            "Words: 0.017*\"learn\" + 0.010*\"algorithm\" + 0.010*\"network\" + 0.010*\"model\" + 0.006*\"task\" + 0.006*\"function\" + 0.006*\"train\" + 0.005*\"data\" + 0.005*\"problem\" + 0.005*\"method\"\n",
            "Topic: 7 \n",
            "Words: 0.012*\"model\" + 0.011*\"algorithm\" + 0.011*\"learn\" + 0.009*\"data\" + 0.008*\"function\" + 0.007*\"method\" + 0.006*\"optim\" + 0.006*\"comput\" + 0.006*\"sampl\" + 0.005*\"result\"\n",
            "Topic: 8 \n",
            "Words: 0.017*\"model\" + 0.011*\"estim\" + 0.009*\"distribut\" + 0.008*\"algorithm\" + 0.008*\"method\" + 0.007*\"learn\" + 0.007*\"sampl\" + 0.006*\"function\" + 0.006*\"approxim\" + 0.006*\"optim\"\n",
            "Topic: 9 \n",
            "Words: 0.015*\"network\" + 0.010*\"model\" + 0.010*\"learn\" + 0.007*\"function\" + 0.007*\"input\" + 0.006*\"neural\" + 0.006*\"train\" + 0.006*\"unit\" + 0.005*\"layer\" + 0.005*\"vector\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA with TF-IDF corpus"
      ],
      "metadata": {
        "id": "ytdMhJDh0LNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ],
      "metadata": {
        "id": "oGsK3tNWxqKO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LqiiSCnxuNl",
        "outputId": "e5381c28-95cc-4237-bacc-f75f70a48076"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.001*\"kernel\" + 0.001*\"imag\" + 0.001*\"neuron\" + 0.000*\"network\" + 0.000*\"train\" + 0.000*\"cluster\" + 0.000*\"graph\" + 0.000*\"featur\" + 0.000*\"rank\" + 0.000*\"label\"\n",
            "Topic: 1 Word: 0.001*\"neuron\" + 0.001*\"polici\" + 0.000*\"spike\" + 0.000*\"network\" + 0.000*\"graph\" + 0.000*\"kernel\" + 0.000*\"layer\" + 0.000*\"tree\" + 0.000*\"reward\" + 0.000*\"label\"\n",
            "Topic: 2 Word: 0.000*\"cluster\" + 0.000*\"kernel\" + 0.000*\"imag\" + 0.000*\"network\" + 0.000*\"neuron\" + 0.000*\"matrix\" + 0.000*\"convex\" + 0.000*\"layer\" + 0.000*\"train\" + 0.000*\"theorem\"\n",
            "Topic: 3 Word: 0.001*\"neuron\" + 0.001*\"polici\" + 0.001*\"imag\" + 0.000*\"cluster\" + 0.000*\"network\" + 0.000*\"motion\" + 0.000*\"action\" + 0.000*\"layer\" + 0.000*\"kernel\" + 0.000*\"train\"\n",
            "Topic: 4 Word: 0.001*\"kernel\" + 0.001*\"imag\" + 0.001*\"neuron\" + 0.001*\"cluster\" + 0.000*\"train\" + 0.000*\"regret\" + 0.000*\"network\" + 0.000*\"featur\" + 0.000*\"layer\" + 0.000*\"classifi\"\n",
            "Topic: 5 Word: 0.001*\"cluster\" + 0.001*\"imag\" + 0.001*\"neuron\" + 0.000*\"network\" + 0.000*\"polici\" + 0.000*\"graph\" + 0.000*\"spike\" + 0.000*\"kernel\" + 0.000*\"mixtur\" + 0.000*\"train\"\n",
            "Topic: 6 Word: 0.000*\"network\" + 0.000*\"imag\" + 0.000*\"kernel\" + 0.000*\"cell\" + 0.000*\"graph\" + 0.000*\"train\" + 0.000*\"tree\" + 0.000*\"neuron\" + 0.000*\"messag\" + 0.000*\"classifi\"\n",
            "Topic: 7 Word: 0.000*\"neuron\" + 0.000*\"submodular\" + 0.000*\"imag\" + 0.000*\"spike\" + 0.000*\"convex\" + 0.000*\"regret\" + 0.000*\"loss\" + 0.000*\"layer\" + 0.000*\"network\" + 0.000*\"rank\"\n",
            "Topic: 8 Word: 0.001*\"polici\" + 0.001*\"imag\" + 0.001*\"label\" + 0.001*\"kernel\" + 0.001*\"cluster\" + 0.000*\"neuron\" + 0.000*\"network\" + 0.000*\"graph\" + 0.000*\"train\" + 0.000*\"spike\"\n",
            "Topic: 9 Word: 0.001*\"kernel\" + 0.000*\"cluster\" + 0.000*\"classifi\" + 0.000*\"imag\" + 0.000*\"network\" + 0.000*\"train\" + 0.000*\"neuron\" + 0.000*\"featur\" + 0.000*\"graph\" + 0.000*\"matrix\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSA with Bag of Words Corpus"
      ],
      "metadata": {
        "id": "eneiSKSy0RQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsa_model = gensim.models.LsiModel(bow_corpus, num_topics=10, id2word=dictionary)"
      ],
      "metadata": {
        "id": "caJR7yw0xvqZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lsa_model.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XozPGz5Lx_xe",
        "outputId": "143abe76-ccc5-47cb-a817-4bed8a077c6a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.316*\"model\" + 0.249*\"learn\" + 0.215*\"algorithm\" + 0.183*\"function\" + 0.170*\"data\" + 0.136*\"method\" + 0.129*\"network\" + 0.129*\"problem\" + 0.128*\"result\" + 0.127*\"distribut\"\n",
            "Topic: 1 Word: -0.549*\"model\" + 0.395*\"algorithm\" + -0.213*\"network\" + -0.194*\"imag\" + 0.184*\"function\" + 0.182*\"problem\" + 0.172*\"optim\" + -0.141*\"train\" + 0.100*\"theorem\" + -0.099*\"neural\"\n",
            "Topic: 2 Word: -0.478*\"model\" + 0.381*\"network\" + 0.337*\"learn\" + 0.235*\"train\" + -0.189*\"estim\" + 0.180*\"imag\" + -0.177*\"distribut\" + 0.148*\"layer\" + 0.137*\"input\" + 0.134*\"featur\"\n",
            "Topic: 3 Word: -0.375*\"imag\" + 0.326*\"network\" + -0.251*\"featur\" + 0.249*\"state\" + -0.211*\"data\" + 0.181*\"neuron\" + 0.179*\"time\" + -0.173*\"label\" + -0.162*\"object\" + 0.150*\"polici\"\n",
            "Topic: 4 Word: 0.496*\"learn\" + -0.317*\"network\" + 0.245*\"polici\" + 0.219*\"model\" + 0.193*\"state\" + 0.165*\"action\" + -0.154*\"neuron\" + -0.148*\"cluster\" + -0.148*\"matrix\" + -0.147*\"estim\"\n",
            "Topic: 5 Word: 0.450*\"algorithm\" + -0.280*\"kernel\" + -0.271*\"estim\" + 0.268*\"cluster\" + -0.256*\"function\" + 0.254*\"imag\" + -0.219*\"learn\" + -0.167*\"sampl\" + -0.154*\"distribut\" + -0.150*\"data\"\n",
            "Topic: 6 Word: -0.422*\"imag\" + -0.297*\"function\" + 0.245*\"learn\" + 0.231*\"network\" + 0.229*\"data\" + 0.220*\"algorithm\" + 0.206*\"cluster\" + -0.181*\"object\" + -0.166*\"optim\" + 0.164*\"label\"\n",
            "Topic: 7 Word: -0.352*\"cluster\" + -0.277*\"kernel\" + 0.268*\"imag\" + -0.256*\"data\" + 0.225*\"network\" + 0.209*\"sampl\" + 0.196*\"estim\" + 0.195*\"distribut\" + -0.192*\"featur\" + -0.177*\"neuron\"\n",
            "Topic: 8 Word: -0.401*\"function\" + -0.359*\"model\" + 0.343*\"sampl\" + 0.255*\"estim\" + 0.236*\"distribut\" + 0.218*\"state\" + 0.190*\"polici\" + 0.179*\"imag\" + -0.138*\"loss\" + -0.135*\"convex\"\n",
            "Topic: 9 Word: 0.314*\"method\" + -0.247*\"neuron\" + -0.222*\"label\" + 0.197*\"matrix\" + 0.167*\"polici\" + -0.166*\"function\" + 0.160*\"network\" + 0.147*\"gradient\" + 0.146*\"state\" + 0.144*\"kernel\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSA with TF-IDF corpus"
      ],
      "metadata": {
        "id": "89Pf3cp-0WqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsa_model_tfidf = gensim.models.LsiModel(corpus_tfidf, num_topics=10, id2word=dictionary)"
      ],
      "metadata": {
        "id": "tmcJb6DwyBZ3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lsa_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82-WncJyDP_",
        "outputId": "3e8a40fc-314f-4bc4-ad7a-450220d9d833"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.146*\"kernel\" + 0.139*\"neuron\" + 0.134*\"imag\" + 0.120*\"cluster\" + 0.105*\"spike\" + 0.103*\"polici\" + 0.099*\"network\" + 0.089*\"train\" + 0.087*\"graph\" + 0.087*\"layer\"\n",
            "Topic: 1 Word: -0.488*\"neuron\" + -0.446*\"spike\" + -0.168*\"fire\" + -0.165*\"cell\" + -0.152*\"synapt\" + -0.148*\"synaps\" + 0.143*\"polici\" + -0.132*\"stimulus\" + 0.116*\"regret\" + 0.103*\"kernel\"\n",
            "Topic: 2 Word: -0.590*\"polici\" + -0.325*\"reward\" + -0.257*\"action\" + -0.222*\"regret\" + -0.219*\"agent\" + 0.160*\"kernel\" + -0.142*\"reinforc\" + 0.141*\"cluster\" + 0.122*\"imag\" + -0.122*\"bandit\"\n",
            "Topic: 3 Word: 0.318*\"imag\" + -0.271*\"spike\" + -0.233*\"regret\" + -0.178*\"kernel\" + 0.172*\"layer\" + 0.171*\"polici\" + -0.159*\"neuron\" + -0.145*\"convex\" + -0.119*\"theorem\" + 0.101*\"segment\"\n",
            "Topic: 4 Word: -0.483*\"cluster\" + 0.416*\"regret\" + -0.304*\"polici\" + 0.188*\"bandit\" + -0.169*\"kernel\" + 0.132*\"loss\" + 0.130*\"imag\" + 0.128*\"layer\" + -0.125*\"spike\" + -0.125*\"graph\"\n",
            "Topic: 5 Word: -0.585*\"kernel\" + 0.497*\"cluster\" + 0.215*\"regret\" + -0.163*\"polici\" + 0.123*\"graph\" + 0.114*\"bandit\" + 0.112*\"tree\" + 0.108*\"queri\" + 0.103*\"submodular\" + 0.098*\"kmean\"\n",
            "Topic: 6 Word: -0.429*\"kernel\" + -0.344*\"cluster\" + -0.242*\"regret\" + -0.226*\"imag\" + 0.142*\"posterior\" + -0.125*\"bandit\" + 0.116*\"topic\" + 0.103*\"latent\" + 0.103*\"infer\" + 0.098*\"bayesian\"\n",
            "Topic: 7 Word: 0.259*\"topic\" + 0.217*\"spike\" + 0.208*\"kernel\" + 0.189*\"document\" + 0.187*\"posterior\" + 0.163*\"regret\" + 0.154*\"latent\" + -0.130*\"convex\" + -0.128*\"norm\" + 0.126*\"bayesian\"\n",
            "Topic: 8 Word: 0.208*\"imag\" + -0.188*\"tree\" + -0.185*\"network\" + -0.171*\"graph\" + -0.152*\"node\" + -0.147*\"layer\" + -0.147*\"kernel\" + -0.145*\"nod\" + -0.125*\"label\" + 0.121*\"latent\"\n",
            "Topic: 9 Word: 0.310*\"spike\" + -0.210*\"regret\" + -0.202*\"kernel\" + 0.200*\"label\" + 0.196*\"polici\" + 0.174*\"imag\" + 0.148*\"queri\" + 0.144*\"rank\" + -0.130*\"cluster\" + 0.130*\"classifi\"\n"
          ]
        }
      ]
    }
  ]
}